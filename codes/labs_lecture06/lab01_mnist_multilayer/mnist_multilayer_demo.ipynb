{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01 : MNIST multi-layer -- demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    # find automatically the path of the folder containing \"file_name\" :\n",
    "    file_name = 'mnist_multilayer_demo.ipynb'\n",
    "    import subprocess\n",
    "    path_to_file = subprocess.check_output('find . -type f -name ' + str(file_name), shell=True).decode(\"utf-8\")\n",
    "    path_to_file = path_to_file.replace(file_name,\"\").replace('\\n',\"\")\n",
    "    # if previous search failed or too long, comment the previous line and simply write down manually the path below :\n",
    "    #path_to_file = '/content/gdrive/My Drive/AI6103_2020_codes/codes/labs_lecture06/lab01_mnist_multilayer'\n",
    "    print(path_to_file)\n",
    "    # change current path to the folder containing \"file_name\"\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import time\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import check_mnist_dataset_exists\n",
    "data_path=check_mnist_dataset_exists()\n",
    "\n",
    "train_data=torch.load(data_path+'mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'mnist/train_label.pt')\n",
    "test_data=torch.load(data_path+'mnist/test_data.pt')\n",
    "test_label=torch.load(data_path+'mnist/test_label.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a two layer net class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class two_layer_net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size,  output_size):\n",
    "        super(two_layer_net , self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(  input_size   , hidden_size  , bias=False  )\n",
    "        self.layer2 = nn.Linear(  hidden_size  , output_size   , bias=False  )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y       = self.layer1(x)\n",
    "        y_hat   = F.relu(y)\n",
    "        scores  = self.layer2(y_hat)\n",
    "        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the net (recall that a one layer net had 7,840 parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_layer_net(\n",
      "  (layer1): Linear(in_features=784, out_features=50, bias=False)\n",
      "  (layer2): Linear(in_features=50, out_features=10, bias=False)\n",
      ")\n",
      "There are 39700 (0.04 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "net=two_layer_net(784,50,10)\n",
    "\n",
    "print(net)\n",
    "utils.display_num_param(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the criterion, optimizer, batchsize, learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer=torch.optim.SGD( net.parameters() , lr=0.01 )\n",
    "\n",
    "bs=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test_set():\n",
    "\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "\n",
    "    for i in range(0,10000,bs):\n",
    "\n",
    "        minibatch_data =  test_data[i:i+bs]\n",
    "        minibatch_label= test_label[i:i+bs]\n",
    "\n",
    "        inputs = minibatch_data.view(bs,784)\n",
    "\n",
    "        scores=net( inputs ) \n",
    "\n",
    "        error = utils.get_error( scores , minibatch_label)\n",
    "\n",
    "        running_error += error.item()\n",
    "\n",
    "        num_batches+=1\n",
    "\n",
    "\n",
    "    total_error = running_error/num_batches\n",
    "    print( 'test error  = ', total_error*100 ,'percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "epoch= 0 \t time= 1.6497702598571777 \t loss= 0.711558502924939 \t error= 17.056666823228202 percent\n",
      "test error  =  9.920000386238097 percent\n",
      " \n",
      "epoch= 5 \t time= 9.812540531158447 \t loss= 0.22243331476331998 \t error= 6.235000773270925 percent\n",
      "test error  =  6.050000536441804 percent\n",
      " \n",
      "epoch= 10 \t time= 18.56841206550598 \t loss= 0.15888590059801935 \t error= 4.57333407998085 percent\n",
      "test error  =  4.690000593662262 percent\n",
      " \n",
      "epoch= 15 \t time= 27.429263830184937 \t loss= 0.12429573758660505 \t error= 3.461667311191559 percent\n",
      "test error  =  3.9300005555152895 percent\n",
      " \n",
      "epoch= 20 \t time= 39.41819477081299 \t loss= 0.10259648355911485 \t error= 2.8650005678335826 percent\n",
      "test error  =  3.530000555515289 percent\n",
      " \n",
      "epoch= 25 \t time= 51.523603200912476 \t loss= 0.08749556159220326 \t error= 2.440000516176224 percent\n",
      "test error  =  3.280000495910645 percent\n",
      " \n",
      "epoch= 30 \t time= 61.62696957588196 \t loss= 0.07587626359782493 \t error= 2.096667100985845 percent\n",
      "test error  =  3.000000536441803 percent\n",
      " \n",
      "epoch= 35 \t time= 72.87083315849304 \t loss= 0.06684813559534572 \t error= 1.848333748181661 percent\n",
      "test error  =  2.800000512599945 percent\n",
      " \n",
      "epoch= 40 \t time= 83.10293126106262 \t loss= 0.05934853586849446 \t error= 1.650000367561976 percent\n",
      "test error  =  2.6000004768371583 percent\n",
      " \n",
      "epoch= 45 \t time= 94.099862575531 \t loss= 0.053531215316829424 \t error= 1.4766670028368631 percent\n",
      "test error  =  2.7300004720687867 percent\n",
      " \n",
      "epoch= 50 \t time= 105.38909482955933 \t loss= 0.048413248571159785 \t error= 1.3133336285750072 percent\n",
      "test error  =  2.6500004649162294 percent\n",
      " \n",
      "epoch= 55 \t time= 117.32583379745483 \t loss= 0.04383592207508627 \t error= 1.1383335888385773 percent\n",
      "test error  =  2.5900004744529723 percent\n",
      " \n",
      "epoch= 60 \t time= 128.3480589389801 \t loss= 0.03984016436840951 \t error= 1.0383335729440053 percent\n",
      "test error  =  2.620000457763672 percent\n",
      " \n",
      "epoch= 65 \t time= 139.31212162971497 \t loss= 0.03642324481282655 \t error= 0.953333556652069 percent\n",
      "test error  =  2.6400004386901856 percent\n",
      " \n",
      "epoch= 70 \t time= 150.30900239944458 \t loss= 0.033135810852312715 \t error= 0.8183335264523824 percent\n",
      "test error  =  2.570000469684601 percent\n",
      " \n",
      "epoch= 75 \t time= 159.37174081802368 \t loss= 0.030367276311677415 \t error= 0.7150001684824625 percent\n",
      "test error  =  2.5700004577636717 percent\n",
      " \n",
      "epoch= 80 \t time= 168.53891134262085 \t loss= 0.027895652132467755 \t error= 0.6316668172677358 percent\n",
      "test error  =  2.4900004506111144 percent\n",
      " \n",
      "epoch= 85 \t time= 179.2870593070984 \t loss= 0.025671729544429884 \t error= 0.575000137090683 percent\n",
      "test error  =  2.5800004720687864 percent\n",
      " \n",
      "epoch= 90 \t time= 191.86663508415222 \t loss= 0.023607624819604097 \t error= 0.48833344777425125 percent\n",
      "test error  =  2.4900004625320435 percent\n",
      " \n",
      "epoch= 95 \t time= 202.26947259902954 \t loss= 0.021727839715592077 \t error= 0.3966667612393697 percent\n",
      "test error  =  2.560000455379486 percent\n",
      " \n",
      "epoch= 100 \t time= 214.63725471496582 \t loss= 0.02020685299912778 \t error= 0.38500009179115297 percent\n",
      "test error  =  2.5900004625320436 percent\n",
      " \n",
      "epoch= 105 \t time= 224.4825005531311 \t loss= 0.018627467102701 \t error= 0.31000007192293805 percent\n",
      "test error  =  2.5300004720687865 percent\n",
      " \n",
      "epoch= 110 \t time= 234.50983691215515 \t loss= 0.017381393534053737 \t error= 0.26500006318092345 percent\n",
      "test error  =  2.5300004839897157 percent\n",
      " \n",
      "epoch= 115 \t time= 245.70407366752625 \t loss= 0.01611657835377264 \t error= 0.23666672309239709 percent\n",
      "test error  =  2.560000503063202 percent\n",
      " \n",
      "epoch= 120 \t time= 256.0671772956848 \t loss= 0.015017380636256955 \t error= 0.2100000500679016 percent\n",
      "test error  =  2.5900004744529723 percent\n",
      " \n",
      "epoch= 125 \t time= 267.7602367401123 \t loss= 0.013863327423211254 \t error= 0.17500004172325134 percent\n",
      "test error  =  2.5900004625320436 percent\n",
      " \n",
      "epoch= 130 \t time= 279.24078822135925 \t loss= 0.01301345183684316 \t error= 0.1383333663145701 percent\n",
      "test error  =  2.47000048160553 percent\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(200):\n",
    "    \n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    \n",
    "    shuffled_indices=torch.randperm(60000)\n",
    " \n",
    "    for count in range(0,60000,bs):\n",
    "        \n",
    "        # forward and backward pass\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        indices=shuffled_indices[count:count+bs]\n",
    "        minibatch_data =  train_data[indices]\n",
    "        minibatch_label= train_label[indices]\n",
    "\n",
    "        inputs = minibatch_data.view(bs,784)\n",
    "\n",
    "        inputs.requires_grad_()\n",
    "\n",
    "        scores=net( inputs ) \n",
    "\n",
    "        loss =  criterion( scores , minibatch_label) \n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        # compute some stats\n",
    "        \n",
    "        running_loss += loss.detach().item()\n",
    "               \n",
    "        error = utils.get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "        \n",
    "        num_batches+=1\n",
    "    \n",
    "    \n",
    "    # once the epoch is finished we divide the \"running quantities\"\n",
    "    # by the number of batches\n",
    "    \n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    elapsed_time = time.time() - start\n",
    "    \n",
    "    # every 10 epoch we display the stats \n",
    "    # and compute the error rate on the test set  \n",
    "    \n",
    "    if epoch % 5 == 0 : \n",
    "    \n",
    "        print(' ')\n",
    "        \n",
    "        print('epoch=',epoch, '\\t time=', elapsed_time,\n",
    "              '\\t loss=', total_loss , '\\t error=', total_error*100 ,'percent')\n",
    "        \n",
    "        eval_on_test_set()\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose image at random from the test set and see how good/bad are the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a picture at random\n",
    "idx=randint(0, 10000-1)\n",
    "im=test_data[idx]\n",
    "\n",
    "# diplay the picture\n",
    "utils.show(im)\n",
    "\n",
    "# feed it to the net and display the confidence scores\n",
    "scores =  net( im.view(1,784)) \n",
    "probs= F.softmax(scores, dim=1)\n",
    "print(probs.shape)\n",
    "utils.show_prob_mnist(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
