{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JhPXB9mng7Py"
   },
   "source": [
    "\n",
    "## AI6103 : Deep Learning and Applications\n",
    "##Â Xavier Bresson\n",
    "\n",
    "\n",
    "## Coding Test 1\n",
    "Date: October 8th, 2020<br>\n",
    "\n",
    "*Instructions* <br>\n",
    "Name: Do not forget to add your name to the notebook file \"coding_test1_AI6103_YOUR_NAME.ipynb\".<br>\n",
    "Questions: This notebook has 10 questions.<br>\n",
    "Answers: Write the answers to each question in this notebook.<br>\n",
    "Type: This test is individual and open-book.<br>\n",
    "Grading: 1 point for each question.<br>\n",
    "Output/Timestamp: There is no point if the code has no output (the cell was not executed) or the timestamp is beyond 8:15pm.<br>\n",
    "Delivery: Upload your notebook to https://drive.google.com/drive/folders/1XkFvpkx17T6lFYakV4CV4JDeBub-t64G by 8:20pm. <br>\n",
    "Remark: **If certain conditions of the questions (for eg. hyperparameter values) are not stated, you are free to choose anything you want.**<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TT3HcmXNhNxp"
   },
   "source": [
    "### Question 1\n",
    "\n",
    "Create a PyTorch tensor $x$ of type FloatTensor, size [2, 5, 7] and filled with value 1. Print the tensor $x$ and its type. Convert the same tensor $x$ to type LongTensor and print its value and type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 675,
     "status": "ok",
     "timestamp": 1600109702676,
     "user": {
      "displayName": "Vijay Prakash Dwivedi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgfLL5UlJ0cWGCM7ABRbVFcbAS9vkLq7ias9ewKNA=s64",
      "userId": "03190496352220804755"
     },
     "user_tz": -480
    },
    "id": "vH-tgwa9gf4L",
    "outputId": "22855a52-17af-4e45-d011-3edc6d8f5fb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-08--20-17-23\n",
      "tensor([[[1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.]]])\n",
      "torch.FloatTensor\n",
      "tensor([[[1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1]]])\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "x = torch.ones(2,5,7) \n",
    "print(x) \n",
    "print(x.type()) \n",
    "\n",
    "x = x.long() \n",
    "print(x) \n",
    "print(x.type()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B3tPn7qa2sLk"
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Given a color image $x$ represented by a tensor of size (3, 28, 28), with 3 color channels (red, green and blue) and a grid domain of 28 pixels by 28 pixels. \n",
    "\n",
    "Transform the image tensor $x$ into a vector of 2,352 elements and print its size.\n",
    "\n",
    "Transform back the vector to an image tensor of size (3, 28, 28) and print its size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 833,
     "status": "ok",
     "timestamp": 1600108253961,
     "user": {
      "displayName": "Vijay Prakash Dwivedi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgfLL5UlJ0cWGCM7ABRbVFcbAS9vkLq7ias9ewKNA=s64",
      "userId": "03190496352220804755"
     },
     "user_tz": -480
    },
    "id": "djho9-rx3V6Z",
    "outputId": "a7e1e68a-8ce3-427f-8e11-a394c8826bc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-08--20-17-23\n",
      "torch.Size([2352])\n",
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "\n",
    "x = torch.rand(3,28,28) # given color image\n",
    "\n",
    "# YOUR CODE HERE\n",
    "vectorized_x = x.view(2352) # 28*28*3 = 2352\n",
    "print(vectorized_x.size())\n",
    "\n",
    "original_x = vectorized_x.view(3,28,28)\n",
    "print(original_x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5LNc-Fo7mT1"
   },
   "source": [
    "### Question 3\n",
    "\n",
    "Consider the score vector $s=[-1.2,4.5,2.3,-0.2]$ to be the output of a 4-class classification network. Convert the score vector $s$ into a probability vector with the softmax operator. Print the probabilities. \n",
    "\n",
    "Implement a Python function that returns the index of the class with the highest probability. Print the index of the highest probability for the above score vector $s$. Note that the 4 classes are indexed with integer values $\\{0,1,2,3\\}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1156,
     "status": "ok",
     "timestamp": 1600143105845,
     "user": {
      "displayName": "Vijay Prakash Dwivedi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgfLL5UlJ0cWGCM7ABRbVFcbAS9vkLq7ias9ewKNA=s64",
      "userId": "03190496352220804755"
     },
     "user_tz": -480
    },
    "id": "L67NCs9r7myO",
    "outputId": "ff9a3273-bb24-4cb8-e113-b26ec3bafeed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-08--20-17-23\n",
      "tensor([0.0030, 0.8903, 0.0986, 0.0081])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "\n",
    "s = torch.Tensor([-1.2,4.5,2.3,-0.2]) \n",
    "\n",
    "# YOUR CODE HERE\n",
    "prob = torch.softmax(s, dim=0)\n",
    "print(prob)\n",
    "\n",
    "def return_max_index(prob):\n",
    "    index_max_prob = torch.argmax(prob, dim=0)\n",
    "    return index_max_prob\n",
    "print(return_max_index(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Implement a Python function for the activation function $$\\sigma(x)=\\frac{2e^{x}-e^{-x}}{2e^{x}+e^{-x}}$$\n",
    "\n",
    "Print the activation values of the input tensor $x=[2.5,-1.2,0.0,-8.2]$ with function $\\sigma$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-08--20-17-23\n",
      "tensor([ 0.9933, -0.6929,  0.3333, -1.0000])\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "\n",
    "x = torch.Tensor([2.5,-1.2,0.0,-8.2])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "def sigma(x):\n",
    "    return ( 2*torch.exp(x) - torch.exp(-x) ) / ( 2*torch.exp(x) + torch.exp(-x) )\n",
    "print(sigma(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_dDEN-vne48"
   },
   "source": [
    "### Question 5\n",
    "\n",
    "Implement a PyTorch class for the following layer\n",
    "\n",
    "$$s = \\sigma(W x + b)$$\n",
    "\n",
    "with the non-linear activation function $\\sigma$ defined in Question 4. \n",
    "\n",
    "Print the output tensor $s$ of dimension 2 given the input tensor $x=[2.3,-1.4,3.9]$.\n",
    "\n",
    "Note that $W$ and $b$ can be any (random) tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 826,
     "status": "ok",
     "timestamp": 1600107092190,
     "user": {
      "displayName": "Vijay Prakash Dwivedi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgfLL5UlJ0cWGCM7ABRbVFcbAS9vkLq7ias9ewKNA=s64",
      "userId": "03190496352220804755"
     },
     "user_tz": -480
    },
    "id": "ZwCjd9Clgjnx",
    "outputId": "3a6d4b04-ab2d-49a9-94a6-6ec527548154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-08--20-17-24\n",
      "tensor([-0.7523, -0.9943], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "\n",
    "x = torch.Tensor([2.3,-1.4,3.9])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "def sigma(x):\n",
    "    return ( 2*torch.exp(x) - torch.exp(-x) ) / ( 2*torch.exp(x) + torch.exp(-x) )\n",
    "\n",
    "class one_layer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(one_layer, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        s = sigma(y)\n",
    "        return s\n",
    "\n",
    "net = one_layer(3,2)\n",
    "s = net(x)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Given a minibatch $s=[ [3.6,-1.1], [-2.1,6.0] ]$ of scores of 2 data points with 2 classes. Compute the mean cross entropy value for this minibatch with the labels $[0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-08--20-17-24\n",
      "tensor(0.0047)\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "\n",
    "score = torch.Tensor([[3.6,-1.1], [-2.1,6.0]])\n",
    "label = torch.LongTensor([0,1])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "loss = nn.CrossEntropyLoss()\n",
    "mean_cross_entropy = loss(score,label)\n",
    "print(mean_cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jzJOcN45z-i1"
   },
   "source": [
    "### Question 7\n",
    "\n",
    "Implement a class of 3-layer MLP with the activation function of Question 4 such that\n",
    "\n",
    "$$s = W_3\\sigma(W_2\\sigma(W_1 x + b_1)+b_2)+b_3)$$\n",
    "\n",
    "Instantiate a network with 784 as input dimension, 25 as hidden dimension and 10 as output dimension. Print the network and the total number of parameters.\n",
    "\n",
    "Use 10 epochs to train the network with batch size 100 and learning rate 0.01. Print the loss and error of the training set after 10 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1044,
     "status": "ok",
     "timestamp": 1600148408449,
     "user": {
      "displayName": "Vijay Prakash Dwivedi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgfLL5UlJ0cWGCM7ABRbVFcbAS9vkLq7ias9ewKNA=s64",
      "userId": "03190496352220804755"
     },
     "user_tz": -480
    },
    "id": "YnPK0d0Igkkw",
    "outputId": "e00e737f-eda0-48e0-cd7e-68b2db4b5e28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-08--20-17-25\n",
      "three_layer_MLP(\n",
      "  (layer1): Linear(in_features=784, out_features=25, bias=True)\n",
      "  (layer2): Linear(in_features=25, out_features=25, bias=True)\n",
      "  (layer3): Linear(in_features=25, out_features=10, bias=True)\n",
      ")\n",
      "There are 20535 (0.02 million) parameters in this neural network\n",
      "None\n",
      "epoch= 0  loss= 1.9291024629275004  error= 52.43000003695488\n",
      "epoch= 1  loss= 1.0625081452727319  error= 21.958333442608517\n",
      "epoch= 2  loss= 0.6795384620626768  error= 15.116666833559671\n",
      "epoch= 3  loss= 0.5272815120220185  error= 12.704999973376593\n",
      "epoch= 4  loss= 0.4486186729868253  error= 11.336666603883106\n",
      "epoch= 5  loss= 0.40031186463932195  error= 10.479999939600626\n",
      "epoch= 6  loss= 0.36759608464936416  error= 9.833333204189938\n",
      "epoch= 7  loss= 0.3435661366333564  error= 9.358333249886831\n",
      "epoch= 8  loss= 0.3247355673710505  error= 8.96166655421257\n",
      "epoch= 9  loss= 0.309600283652544  error= 8.576666583617529\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from utils import *\n",
    "data_path=check_mnist_dataset_exists()\n",
    "train_data=torch.load(data_path+'mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'mnist/train_label.pt')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "def sigma(x):\n",
    "    return ( 2*torch.exp(x) - torch.exp(-x) ) / ( 2*torch.exp(x) + torch.exp(-x) )\n",
    "\n",
    "class three_layer_MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(three_layer_MLP , self).__init__()\n",
    "        self.layer1 = nn.Linear(  input_size, hidden_size )\n",
    "        self.layer2 = nn.Linear(  hidden_size, hidden_size )\n",
    "        self.layer3 = nn.Linear(  hidden_size, output_size )\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = sigma(x)\n",
    "        x = self.layer2(x)\n",
    "        x = sigma(x)\n",
    "        score = self.layer3(x)\n",
    "        return score\n",
    "\n",
    "net = three_layer_MLP(784,25,10)\n",
    "print(net)\n",
    "print(utils.display_num_param(net))\n",
    "\n",
    "bs = 100\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD( net.parameters() , lr=0.01 )\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    shuffled_indices=torch.randperm(60000)\n",
    "    for count in range(0,60000,bs):\n",
    "        optimizer.zero_grad()\n",
    "        indices = shuffled_indices[count:count+bs]\n",
    "        minibatch_data = train_data[indices]\n",
    "        minibatch_label = train_label[indices]\n",
    "        inputs = minibatch_data.view(bs,784)\n",
    "        inputs.requires_grad_()\n",
    "        scores = net( inputs ) \n",
    "        loss = criterion( scores , minibatch_label) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.detach().item()\n",
    "        error = get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "        num_batches+=1\n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    print('epoch=',epoch, ' loss=', total_loss , ' error=', total_error*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Implement a class of 3-layer MLP with the ReLU activation function. Instantiate a network with 784 as input dimension, 7 as hidden dimension and 10 as output dimension. \n",
    "\n",
    "Use 20 epochs to train the network with batch size 100.\n",
    "\n",
    "Implement the following learning rate (lr) schedule. Start with an initial lr of 0.5. Reduce the lr value at each epoch by a factor of 2.0 (that is lr/2.0) if the error on the validation set does not decrease. Print the loss and the error of the training set, and the lr after 20 epochs. \n",
    "\n",
    "What is the error of the training set if the initial lr is 0.5 and no learning rate schedule is used? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-08--20-17-36\n",
      "Size of training set torch.Size([59000, 28, 28])\n",
      "Size of validation set torch.Size([1000, 28, 28])\n",
      "three_layer_MLP(\n",
      "  (layer1): Linear(in_features=784, out_features=7, bias=True)\n",
      "  (layer2): Linear(in_features=7, out_features=7, bias=True)\n",
      "  (layer3): Linear(in_features=7, out_features=10, bias=True)\n",
      ")\n",
      "There are 5631 (0.01 million) parameters in this neural network\n",
      "None\n",
      "epoch= 0  loss= 1.4957796851457175  error= 61.569491513704854  lr= 0.5\n",
      "epoch= 1  loss= 1.4479338165056908  error= 63.69491518554041  lr= 0.25\n",
      "epoch= 2  loss= 1.3131546325602774  error= 56.7745764073679  lr= 0.25\n",
      "epoch= 3  loss= 1.2515432040570147  error= 51.871186434212376  lr= 0.25\n",
      "epoch= 4  loss= 1.1989067771677244  error= 50.01355915756549  lr= 0.125\n",
      "epoch= 5  loss= 1.0542596116914587  error= 43.71694923457453  lr= 0.125\n",
      "epoch= 6  loss= 1.0364945900642266  error= 41.95593225753914  lr= 0.125\n",
      "epoch= 7  loss= 0.9825358574673281  error= 38.77966097855972  lr= 0.0625\n",
      "epoch= 8  loss= 0.8829074942459494  error= 33.969491558559874  lr= 0.0625\n",
      "epoch= 9  loss= 0.865312593468165  error= 33.628813371819966  lr= 0.0625\n",
      "epoch= 10  loss= 0.8524686081934784  error= 33.02372875860182  lr= 0.03125\n",
      "epoch= 11  loss= 0.8295132024813506  error= 32.04067787881625  lr= 0.03125\n",
      "epoch= 12  loss= 0.824101190950911  error= 31.89322022058196  lr= 0.03125\n",
      "epoch= 13  loss= 0.8194110893597037  error= 31.56779622627517  lr= 0.03125\n",
      "epoch= 14  loss= 0.8141789269649377  error= 31.393220202397494  lr= 0.03125\n",
      "epoch= 15  loss= 0.8106254952438807  error= 31.352542163962028  lr= 0.015625\n",
      "epoch= 16  loss= 0.8022513338064743  error= 30.554237123263086  lr= 0.015625\n",
      "epoch= 17  loss= 0.8001191091739526  error= 30.310169367466944  lr= 0.015625\n",
      "epoch= 18  loss= 0.7985069404214116  error= 30.027118406053315  lr= 0.015625\n",
      "epoch= 19  loss= 0.7960652389768826  error= 30.059321916709514  lr= 0.0078125\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from utils import *\n",
    "data_path=check_fashion_mnist_dataset_exists()\n",
    "train_data=torch.load(data_path+'fashion-mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'fashion-mnist/train_label.pt')\n",
    "idx = torch.arange(60000)\n",
    "idx_train = idx[:59000]\n",
    "idx_val = idx[59000:]\n",
    "val_data = train_data[idx_val]\n",
    "val_label = train_label[idx_val]\n",
    "train_data = train_data[idx_train]\n",
    "train_label = train_label[idx_train]\n",
    "\n",
    "print('Size of training set',train_data.size())\n",
    "print('Size of validation set',val_data.size())\n",
    "\n",
    "# YOUR CODE HERE\n",
    "class three_layer_MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(three_layer_MLP , self).__init__()\n",
    "        self.layer1 = nn.Linear(  input_size, hidden_size )\n",
    "        self.layer2 = nn.Linear(  hidden_size, hidden_size )\n",
    "        self.layer3 = nn.Linear(  hidden_size, output_size )\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.relu(x)\n",
    "        score = self.layer3(x)\n",
    "        return score\n",
    "\n",
    "net = three_layer_MLP(784,7,10)\n",
    "print(net)\n",
    "print(utils.display_num_param(net))\n",
    "\n",
    "bs = 100\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.5\n",
    "optimizer=torch.optim.SGD( net.parameters() , lr=lr )\n",
    "\n",
    "val_error_old = 0\n",
    "for epoch in range(20):\n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    shuffled_indices=torch.randperm(59000)            \n",
    "    for count in range(0,59000,bs):\n",
    "        optimizer.zero_grad()\n",
    "        indices = shuffled_indices[count:count+bs]\n",
    "        minibatch_data = train_data[indices]\n",
    "        minibatch_label = train_label[indices]\n",
    "        inputs = minibatch_data.view(bs,784)\n",
    "        inputs.requires_grad_()\n",
    "        scores = net( inputs ) \n",
    "        loss = criterion( scores , minibatch_label) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.detach().item()\n",
    "        error = get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "        num_batches+=1\n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    \n",
    "    # lr schedule\n",
    "    flag_lrs = True\n",
    "    #flag_lrs = False\n",
    "    if flag_lrs:\n",
    "        if epoch>0:\n",
    "            inputs = val_data.view(1000,784)\n",
    "            inputs.requires_grad_()\n",
    "            scores = net( inputs ) \n",
    "            val_error = 100*get_error( scores.detach() , val_label).item()\n",
    "            if val_error>val_error_old:\n",
    "                lr /= 2\n",
    "                optimizer=torch.optim.SGD( net.parameters() , lr=lr )\n",
    "            val_error_old = val_error\n",
    "\n",
    "    print('epoch=',epoch, ' loss=', total_loss , ' error=', total_error*100, ' lr=', lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the error of the training set if the initial lr is 0.5 and no learning rate schedule is used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-08--20-17-48\n",
      "Size of training set torch.Size([59000, 28, 28])\n",
      "Size of validation set torch.Size([1000, 28, 28])\n",
      "three_layer_MLP(\n",
      "  (layer1): Linear(in_features=784, out_features=7, bias=True)\n",
      "  (layer2): Linear(in_features=7, out_features=7, bias=True)\n",
      "  (layer3): Linear(in_features=7, out_features=10, bias=True)\n",
      ")\n",
      "There are 5631 (0.01 million) parameters in this neural network\n",
      "None\n",
      "epoch= 0  loss= 1.6522785221116016  error= 71.584745685933  lr= 0.5\n",
      "epoch= 1  loss= 1.4188979601455947  error= 65.20677948402145  lr= 0.5\n",
      "epoch= 2  loss= 1.2585962826922787  error= 57.472881583844206  lr= 0.5\n",
      "epoch= 3  loss= 1.2152180659568916  error= 55.46440689240472  lr= 0.5\n",
      "epoch= 4  loss= 1.2183744320424936  error= 55.401694926164915  lr= 0.5\n",
      "epoch= 5  loss= 1.1694380286386457  error= 52.23898324926021  lr= 0.5\n",
      "epoch= 6  loss= 1.1925271027168984  error= 54.18983065475852  lr= 0.5\n",
      "epoch= 7  loss= 1.180211611521446  error= 53.937288118621055  lr= 0.5\n",
      "epoch= 8  loss= 0.959929753764201  error= 40.75932220887329  lr= 0.5\n",
      "epoch= 9  loss= 0.8950881364992109  error= 36.53898297730139  lr= 0.5\n",
      "epoch= 10  loss= 1.1400732754650762  error= 51.077966073812064  lr= 0.5\n",
      "epoch= 11  loss= 1.4146391789791948  error= 65.78983049271471  lr= 0.5\n",
      "epoch= 12  loss= 1.4614564570329958  error= 68.98983062323877  lr= 0.5\n",
      "epoch= 13  loss= 1.4528657757629782  error= 66.75932208360251  lr= 0.5\n",
      "epoch= 14  loss= 1.4657194006240974  error= 66.9864407333277  lr= 0.5\n",
      "epoch= 15  loss= 1.1675589892823817  error= 51.11355933092408  lr= 0.5\n",
      "epoch= 16  loss= 1.2667204749786247  error= 55.023728881852094  lr= 0.5\n",
      "epoch= 17  loss= 1.404563829454325  error= 62.16101716130466  lr= 0.5\n",
      "epoch= 18  loss= 1.5867289737119512  error= 71.83389847561465  lr= 0.5\n",
      "epoch= 19  loss= 1.7281790971755981  error= 79.91694932266817  lr= 0.5\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from utils import *\n",
    "data_path=check_fashion_mnist_dataset_exists()\n",
    "train_data=torch.load(data_path+'fashion-mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'fashion-mnist/train_label.pt')\n",
    "idx = torch.arange(60000)\n",
    "idx_train = idx[:59000]\n",
    "idx_val = idx[59000:]\n",
    "val_data = train_data[idx_val]\n",
    "val_label = train_label[idx_val]\n",
    "train_data = train_data[idx_train]\n",
    "train_label = train_label[idx_train]\n",
    "\n",
    "print('Size of training set',train_data.size())\n",
    "print('Size of validation set',val_data.size())\n",
    "\n",
    "# YOUR CODE HERE\n",
    "class three_layer_MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(three_layer_MLP , self).__init__()\n",
    "        self.layer1 = nn.Linear(  input_size, hidden_size )\n",
    "        self.layer2 = nn.Linear(  hidden_size, hidden_size )\n",
    "        self.layer3 = nn.Linear(  hidden_size, output_size )\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.relu(x)\n",
    "        score = self.layer3(x)\n",
    "        return score\n",
    "\n",
    "net = three_layer_MLP(784,7,10)\n",
    "print(net)\n",
    "print(utils.display_num_param(net))\n",
    "\n",
    "bs = 100\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.5\n",
    "optimizer=torch.optim.SGD( net.parameters() , lr=lr )\n",
    "\n",
    "val_error_old = 0\n",
    "for epoch in range(20):\n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    shuffled_indices=torch.randperm(59000)            \n",
    "    for count in range(0,59000,bs):\n",
    "        optimizer.zero_grad()\n",
    "        indices = shuffled_indices[count:count+bs]\n",
    "        minibatch_data = train_data[indices]\n",
    "        minibatch_label = train_label[indices]\n",
    "        inputs = minibatch_data.view(bs,784)\n",
    "        inputs.requires_grad_()\n",
    "        scores = net( inputs ) \n",
    "        loss = criterion( scores , minibatch_label) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.detach().item()\n",
    "        error = get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "        num_batches+=1\n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    \n",
    "    # lr schedule\n",
    "    flag_lrs = True\n",
    "    flag_lrs = False\n",
    "    if flag_lrs:\n",
    "        if epoch>0:\n",
    "            inputs = val_data.view(1000,784)\n",
    "            inputs.requires_grad_()\n",
    "            scores = net( inputs ) \n",
    "            val_error = 100*get_error( scores.detach() , val_label).item()\n",
    "            if val_error>val_error_old:\n",
    "                lr /= 2\n",
    "                optimizer=torch.optim.SGD( net.parameters() , lr=lr )\n",
    "            val_error_old = val_error\n",
    "\n",
    "    print('epoch=',epoch, ' loss=', total_loss , ' error=', total_error*100, ' lr=', lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Implement a class of 3-layer MLP with the ReLU activation function. Instantiate a network with 784 as input dimension, 25 as hidden dimension and 1 as output dimension. \n",
    "\n",
    "The output dimension is 1 because the problem is changed from a classification task to a regression task. The regression task consists in predicting the class index, here the values 0,1,2,3,...,9 for the ten classes of FASHION-MNIST.\n",
    "\n",
    "Implement the standard regression loss\n",
    "\n",
    "$$ L = \\frac{1}{n}\\sqrt{\\sum_{i=1}^n (s_i - \\textrm{cl}(i))^2}$$\n",
    "\n",
    "where $s_i=\\textrm{3-layer MLP}(x_i)$ is the output of the 3-layer MLP and $\\textrm{cl}(i)$ is the class index of data point $x_i$.\n",
    "\n",
    "Use 10 epochs to train the network with batch size 100 and learning rate 0.001. Print the loss of the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-08--20-17-59\n",
      "epoch= 0  loss= 0.5377967131137847\n",
      "epoch= 1  loss= 0.5271476685007414\n",
      "epoch= 2  loss= 0.5110719858109951\n",
      "epoch= 3  loss= 0.4841665614644686\n",
      "epoch= 4  loss= 0.4366887050867081\n",
      "epoch= 5  loss= 0.36693891485532126\n",
      "epoch= 6  loss= 0.31528640458981194\n",
      "epoch= 7  loss= 0.2902517969409625\n",
      "epoch= 8  loss= 0.2677514855315288\n",
      "epoch= 9  loss= 0.24424728641907373\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from utils import *\n",
    "data_path=check_fashion_mnist_dataset_exists()\n",
    "train_data=torch.load(data_path+'fashion-mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'fashion-mnist/train_label.pt')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "class three_layer_MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(three_layer_MLP , self).__init__()\n",
    "        self.layer1 = nn.Linear(  input_size, hidden_size )\n",
    "        self.layer2 = nn.Linear(  hidden_size, hidden_size )\n",
    "        self.layer3 = nn.Linear(  hidden_size, output_size )\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.relu(x)\n",
    "        score = self.layer3(x)\n",
    "        return score\n",
    "\n",
    "net = three_layer_MLP(784,25,1)\n",
    "bs = 100\n",
    "optimizer=torch.optim.SGD( net.parameters() , lr=0.001 )\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss=0\n",
    "    num_batches=0\n",
    "    shuffled_indices=torch.randperm(60000)            \n",
    "    for count in range(0,60000,bs):\n",
    "        optimizer.zero_grad()\n",
    "        indices = shuffled_indices[count:count+bs]\n",
    "        minibatch_data = train_data[indices]\n",
    "        minibatch_label = train_label[indices]\n",
    "        inputs = minibatch_data.view(bs,784)\n",
    "        inputs.requires_grad_()\n",
    "        scores = net( inputs ) \n",
    "        loss = ( ( scores.squeeze() - minibatch_label.float() )**2 ).sum().sqrt()/ bs\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.detach().item()\n",
    "        num_batches+=1\n",
    "    total_loss = running_loss/num_batches\n",
    "    print('epoch=',epoch, ' loss=', total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Implement a class of 1-layer MLP, that is $$s=Wx+b$$ \n",
    "\n",
    "with no activation function. Instantiate a network with 784 as input dimension and 2 as output dimension. \n",
    "\n",
    "The output dimension is 2 because the task is to classify digits 1s and 7s with 6,000 training data for the class 1 and 600 training data for the class of 7. This classification task is unbalanced. \n",
    "\n",
    "To correct the unbalanced training set, a weighted cross entropy loss is used and defined as\n",
    "\n",
    "$$ L = -\\frac{1}{N}\\sum_{i=1}^N w^{(i)}. \\log \\Big(\\textrm{entry cl($i$) of probability vector } p^{(i)} \\Big)$$\n",
    "\n",
    "where $cl($i$)$ is the class index of the $i^{th}$ training data, $p^{(i)}$ is the probability vector computed by the network, and $w^{(i)}$ is equal to $0.1$ for data belonging to the class of 1s and $w^{(i)}$ equal to $1.0$ for data belonging to the class of 7s.\n",
    "\n",
    "Implement the weighted cross entropy loss. Use 20 epochs to train the network with batch size 100 and learning rate 0.01. Print the weighted cross entropy loss and error value for the training set. Print the error value for the test set.\n",
    "\n",
    "Compute and compare theses values with the standard non-weighted cross entropy loss defined as\n",
    "\n",
    "$$ L = -\\frac{1}{N}\\sum_{i=1}^N \\log \\Big(\\textrm{entry cl($i$) of probability vector } p^{(i)} \\Big)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-08--20-18-06\n",
      "Size of training set: torch.Size([6600, 28, 28])\n",
      "Size of test set: torch.Size([200, 28, 28])\n",
      "epoch= 0  loss= 0.08799879111801133  train_error= 9.24242382699793  test_error= 0.0\n",
      "epoch= 1  loss= 0.06376369303148804  train_error= 9.090909361839294  test_error= 0.0\n",
      "epoch= 2  loss= 0.06192913459557475  train_error= 9.090909090909092  test_error= 0.0\n",
      "epoch= 3  loss= 0.06055420758484891  train_error= 9.090908910288956  test_error= 0.0\n",
      "epoch= 4  loss= 0.059276756689404  train_error= 9.09090954245943  test_error= 0.0\n",
      "epoch= 5  loss= 0.05807738917682207  train_error= 9.090909090909092  test_error= 0.0\n",
      "epoch= 6  loss= 0.056940296100396096  train_error= 9.090908639358751  test_error= 0.0\n",
      "epoch= 7  loss= 0.055879899272412964  train_error= 9.090908910288956  test_error= 0.0\n",
      "epoch= 8  loss= 0.054881979429134815  train_error= 9.090908819978887  test_error= 0.0\n",
      "epoch= 9  loss= 0.05395489290469524  train_error= 9.090909361839294  test_error= 0.0\n",
      "epoch= 10  loss= 0.05309086163161379  train_error= 9.090909361839294  test_error= 0.0\n",
      "epoch= 11  loss= 0.05228940990160812  train_error= 9.106060952851266  test_error= 0.0\n",
      "epoch= 12  loss= 0.05154233733474305  train_error= 9.106060230370725  test_error= 0.0\n",
      "epoch= 13  loss= 0.05085151095056173  train_error= 9.121212182622967  test_error= 0.0\n",
      "epoch= 14  loss= 0.050205407099741875  train_error= 9.121211731072629  test_error= 0.0\n",
      "epoch= 15  loss= 0.04961004119479295  train_error= 9.121211821382696  test_error= 0.0\n",
      "epoch= 16  loss= 0.049055986078173824  train_error= 9.121212002002832  test_error= 0.0\n",
      "epoch= 17  loss= 0.04853771234664953  train_error= 9.136363141464464  test_error= 0.0\n",
      "epoch= 18  loss= 0.04806251061910933  train_error= 9.1363633220846  test_error= 0.0\n",
      "epoch= 19  loss= 0.04760713302389239  train_error= 9.136363412394669  test_error= 0.0\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "from packaging import version\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from utils import *\n",
    "data_path=check_fashion_mnist_dataset_exists()\n",
    "train_data=torch.load(data_path+'fashion-mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'fashion-mnist/train_label.pt')\n",
    "test_data=torch.load(data_path+'fashion-mnist/test_data.pt')\n",
    "test_label=torch.load(data_path+'fashion-mnist/test_label.pt')\n",
    "\n",
    "if version.parse(torch.__version__) < version.parse(\"1.6.0\"):\n",
    "    idx_class0 = (train_label==1-1).nonzero().squeeze()\n",
    "    idx_class1 = (train_label==7-1).nonzero().squeeze()\n",
    "else:\n",
    "    idx_class0 = (train_label==1-1).nonzero(as_tuple=False).squeeze()\n",
    "    idx_class1 = (train_label==7-1).nonzero(as_tuple=False).squeeze()\n",
    "idx_class0 = idx_class0[:6000]\n",
    "idx_class1 = idx_class1[:600]\n",
    "train_data = train_data[torch.cat((idx_class0,idx_class1))]\n",
    "train_label = train_label[torch.cat((idx_class0,idx_class1))]\n",
    "train_label[train_label==1-1] = 0 # class 1 has label 0\n",
    "train_label[train_label==7-1] = 1 # class 7 has label 1\n",
    "\n",
    "if version.parse(torch.__version__) < version.parse(\"1.6.0\"):\n",
    "    idx_class0 = (test_label==1-1).nonzero().squeeze()\n",
    "    idx_class1 = (test_label==7-1).nonzero().squeeze()\n",
    "else:\n",
    "    idx_class0 = (test_label==1-1).nonzero(as_tuple=False).squeeze()\n",
    "    idx_class1 = (test_label==7-1).nonzero(as_tuple=False).squeeze() \n",
    "idx_class0 = idx_class0[:6000]\n",
    "idx_class1 = idx_class1[:600]\n",
    "test_data = test_data[torch.cat((idx_class0,idx_class1))]\n",
    "test_label = test_label[torch.cat((idx_class0,idx_class1))]\n",
    "test_label[test_label==1-1] = 0 # class 1 has label 0\n",
    "test_label[test_label==7-1] = 1 # class 7 has label 1\n",
    "test_data = test_data[:200]\n",
    "test_label = test_label[:200]\n",
    "\n",
    "print('Size of training set:',train_data.size())\n",
    "print('Size of test set:',test_data.size())\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "class one_layer_MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(one_layer_MLP , self).__init__()\n",
    "        self.layer = nn.Linear(  input_size, output_size )\n",
    "    def forward(self, x):\n",
    "        score = self.layer(x)\n",
    "        return score\n",
    "\n",
    "net = one_layer_MLP(784,2)\n",
    "bs = 100\n",
    "optimizer=torch.optim.SGD( net.parameters() , lr=0.01 )\n",
    "\n",
    "for epoch in range(20):\n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    shuffled_indices=torch.randperm(train_data.size(0))            \n",
    "    for count in range(0,train_data.size(0),bs):\n",
    "        optimizer.zero_grad()\n",
    "        indices = shuffled_indices[count:count+bs]\n",
    "        minibatch_data = train_data[indices]\n",
    "        minibatch_label = train_label[indices]\n",
    "        inputs = minibatch_data.view(bs,784)\n",
    "        inputs.requires_grad_()\n",
    "        scores = net( inputs ) \n",
    "        \n",
    "        # weighted cross entropy\n",
    "        p = torch.softmax(scores, dim=1)\n",
    "        log_prob = -torch.log(p)\n",
    "        w = torch.zeros(bs)\n",
    "        w[minibatch_label==0] = 1\n",
    "        w[minibatch_label==1] = 1/10\n",
    "        loss = (w* log_prob[torch.arange(bs),minibatch_label]).mean() # weighted cross entropy\n",
    "        #loss = log_prob[torch.arange(bs),minibatch_label].mean() # un-weighted cross entropy\n",
    "        error = get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.detach().item()\n",
    "        num_batches+=1\n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    \n",
    "    # test error\n",
    "    scores = net( test_data.view(200,784) ) \n",
    "    test_error = get_error( scores.detach() , test_label).item()\n",
    "           \n",
    "    print('epoch=',epoch, ' loss=', total_loss, ' train_error=', 100*total_error, ' test_error=', 100*test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and compare theses values with the standard non-weighted cross entropy loss defined as\n",
    "\n",
    "$$ L = -\\frac{1}{N}\\sum_{i=1}^N \\log \\Big(\\textrm{entry cl($i$) of probability vector } p^{(i)} \\Big)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-08--20-18-07\n",
      "Size of training set: torch.Size([6600, 28, 28])\n",
      "Size of test set: torch.Size([200, 28, 28])\n",
      "epoch= 0  loss= 0.2910975637761029  train_error= 9.757575663653286  test_error= 0.0\n",
      "epoch= 1  loss= 0.23234697386170877  train_error= 8.348484924345305  test_error= 0.0\n",
      "epoch= 2  loss= 0.21319508710593887  train_error= 6.560605764389038  test_error= 0.4999995231628418\n",
      "epoch= 3  loss= 0.20432460071011024  train_error= 6.106060562711773  test_error= 0.9999990463256836\n",
      "epoch= 4  loss= 0.19929645797519974  train_error= 5.818181778445388  test_error= 0.9999990463256836\n",
      "epoch= 5  loss= 0.1957977679416989  train_error= 5.863636099930965  test_error= 1.9999980926513672\n",
      "epoch= 6  loss= 0.1929458256698016  train_error= 5.696969682520086  test_error= 2.499997615814209\n",
      "epoch= 7  loss= 0.19095126460447456  train_error= 5.772726915099404  test_error= 0.9999990463256836\n",
      "epoch= 8  loss= 0.18918638078100752  train_error= 5.742424184625799  test_error= 1.4999985694885254\n",
      "epoch= 9  loss= 0.18798873855760603  train_error= 5.636363408782265  test_error= 1.9999980926513672\n",
      "epoch= 10  loss= 0.18668332504052104  train_error= 5.590908816366484  test_error= 1.9999980926513672\n",
      "epoch= 11  loss= 0.18507849955649086  train_error= 5.757575595017635  test_error= 0.9999990463256836\n",
      "epoch= 12  loss= 0.18422728088317494  train_error= 5.681818362438317  test_error= 1.4999985694885254\n",
      "epoch= 13  loss= 0.18269151178273288  train_error= 5.560605544032472  test_error= 2.499997615814209\n",
      "epoch= 14  loss= 0.18217840327909499  train_error= 5.606060317068389  test_error= 2.499997615814209\n",
      "epoch= 15  loss= 0.18139991119052423  train_error= 5.636363499092333  test_error= 2.499997615814209\n",
      "epoch= 16  loss= 0.1804462347292539  train_error= 5.575757405974648  test_error= 0.9999990463256836\n",
      "epoch= 17  loss= 0.17980594978188025  train_error= 5.530303174799139  test_error= 2.999997138977051\n",
      "epoch= 18  loss= 0.17911178336450548  train_error= 5.636363589402401  test_error= 2.499997615814209\n",
      "epoch= 19  loss= 0.17836928965918947  train_error= 5.5606059955828115  test_error= 2.499997615814209\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "from packaging import version\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from utils import *\n",
    "data_path=check_fashion_mnist_dataset_exists()\n",
    "train_data=torch.load(data_path+'fashion-mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'fashion-mnist/train_label.pt')\n",
    "test_data=torch.load(data_path+'fashion-mnist/test_data.pt')\n",
    "test_label=torch.load(data_path+'fashion-mnist/test_label.pt')\n",
    "\n",
    "if version.parse(torch.__version__) < version.parse(\"1.6.0\"):\n",
    "    idx_class0 = (train_label==1-1).nonzero().squeeze()\n",
    "    idx_class1 = (train_label==7-1).nonzero().squeeze()\n",
    "else:\n",
    "    idx_class0 = (train_label==1-1).nonzero(as_tuple=False).squeeze()\n",
    "    idx_class1 = (train_label==7-1).nonzero(as_tuple=False).squeeze()\n",
    "idx_class0 = idx_class0[:6000]\n",
    "idx_class1 = idx_class1[:600]\n",
    "train_data = train_data[torch.cat((idx_class0,idx_class1))]\n",
    "train_label = train_label[torch.cat((idx_class0,idx_class1))]\n",
    "train_label[train_label==1-1] = 0 # class 1 has label 0\n",
    "train_label[train_label==7-1] = 1 # class 7 has label 1\n",
    "\n",
    "if version.parse(torch.__version__) < version.parse(\"1.6.0\"):\n",
    "    idx_class0 = (test_label==1-1).nonzero().squeeze()\n",
    "    idx_class1 = (test_label==7-1).nonzero().squeeze()\n",
    "else:\n",
    "    idx_class0 = (test_label==1-1).nonzero(as_tuple=False).squeeze()\n",
    "    idx_class1 = (test_label==7-1).nonzero(as_tuple=False).squeeze() \n",
    "idx_class0 = idx_class0[:6000]\n",
    "idx_class1 = idx_class1[:600]\n",
    "test_data = test_data[torch.cat((idx_class0,idx_class1))]\n",
    "test_label = test_label[torch.cat((idx_class0,idx_class1))]\n",
    "test_label[test_label==1-1] = 0 # class 1 has label 0\n",
    "test_label[test_label==7-1] = 1 # class 7 has label 1\n",
    "test_data = test_data[:200]\n",
    "test_label = test_label[:200]\n",
    "\n",
    "print('Size of training set:',train_data.size())\n",
    "print('Size of test set:',test_data.size())\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "class one_layer_MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(one_layer_MLP , self).__init__()\n",
    "        self.layer = nn.Linear(  input_size, output_size )\n",
    "    def forward(self, x):\n",
    "        score = self.layer(x)\n",
    "        return score\n",
    "\n",
    "net = one_layer_MLP(784,2)\n",
    "bs = 100\n",
    "optimizer=torch.optim.SGD( net.parameters() , lr=0.01 )\n",
    "\n",
    "for epoch in range(20):\n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    shuffled_indices=torch.randperm(train_data.size(0))            \n",
    "    for count in range(0,train_data.size(0),bs):\n",
    "        optimizer.zero_grad()\n",
    "        indices = shuffled_indices[count:count+bs]\n",
    "        minibatch_data = train_data[indices]\n",
    "        minibatch_label = train_label[indices]\n",
    "        inputs = minibatch_data.view(bs,784)\n",
    "        inputs.requires_grad_()\n",
    "        scores = net( inputs ) \n",
    "        \n",
    "        # weighted cross entropy\n",
    "        p = torch.softmax(scores, dim=1)\n",
    "        log_prob = -torch.log(p)\n",
    "        w = torch.zeros(bs)\n",
    "        w[minibatch_label==0] = 1\n",
    "        w[minibatch_label==1] = 1/10\n",
    "        #loss = (w* log_prob[torch.arange(bs),minibatch_label]).mean() # weighted cross entropy\n",
    "        loss = log_prob[torch.arange(bs),minibatch_label].mean() # un-weighted cross entropy\n",
    "        error = get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.detach().item()\n",
    "        num_batches+=1\n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    \n",
    "    # test error\n",
    "    scores = net( test_data.view(200,784) ) \n",
    "    test_error = get_error( scores.detach() , test_label).item()\n",
    "           \n",
    "    print('epoch=',epoch, ' loss=', total_loss, ' train_error=', 100*total_error, ' test_error=', 100*test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNd30TjgREYWyAkV0lT4iX6",
   "name": "CE_7454_coding_test_solution_Vijay.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
