{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JhPXB9mng7Py"
   },
   "source": [
    "\n",
    "## AI6103 : Deep Learning and Applications\n",
    "##Â Xavier Bresson\n",
    "\n",
    "\n",
    "## Coding Test 1\n",
    "Date: October 8th, 2020<br>\n",
    "\n",
    "*Instructions* <br>\n",
    "Name: Do not forget to add your name to the notebook file \"coding_test1_AI6103_YOUR_NAME.ipynb\".<br>\n",
    "Questions: This notebook has 10 questions.<br>\n",
    "Answers: Write the answers to each question in this notebook.<br>\n",
    "Type: This test is individual and open-book.<br>\n",
    "Grading: 1 point for each question.<br>\n",
    "Output/Timestamp: There is no point if the code has no output (the cell was not executed) or the timestamp is beyond 8:15pm.<br>\n",
    "Delivery: Upload your notebook to https://drive.google.com/drive/folders/1XkFvpkx17T6lFYakV4CV4JDeBub-t64G by 8:20pm. <br>\n",
    "Remark: **If certain conditions of the questions (for eg. hyperparameter values) are not stated, you are free to choose anything you want.**<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TT3HcmXNhNxp"
   },
   "source": [
    "### Question 1\n",
    "\n",
    "Create a PyTorch tensor $x$ of type FloatTensor, size [2, 5, 7] and filled with value 1. Print the tensor $x$ and its type. Convert the same tensor $x$ to type LongTensor and print its value and type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 675,
     "status": "ok",
     "timestamp": 1600109702676,
     "user": {
      "displayName": "Vijay Prakash Dwivedi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgfLL5UlJ0cWGCM7ABRbVFcbAS9vkLq7ias9ewKNA=s64",
      "userId": "03190496352220804755"
     },
     "user_tz": -480
    },
    "id": "vH-tgwa9gf4L",
    "outputId": "22855a52-17af-4e45-d011-3edc6d8f5fb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-11-26--17-12-20\n",
      "tensor([[[1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1.]]]) torch.FloatTensor\n",
      "tensor([[[1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1]]]) torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "x = torch.ones([2,5,7])\n",
    "print(x, x.type())\n",
    "x = x.long()\n",
    "print(x, x.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B3tPn7qa2sLk"
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Given a color image $x$ represented by a tensor of size (3, 28, 28), with 3 color channels (red, green and blue) and a grid domain of 28 pixels by 28 pixels. \n",
    "\n",
    "Transform the image tensor $x$ into a vector of 2,352 elements and print its size.\n",
    "\n",
    "Transform back the vector to an image tensor of size (3, 28, 28) and print its size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 833,
     "status": "ok",
     "timestamp": 1600108253961,
     "user": {
      "displayName": "Vijay Prakash Dwivedi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgfLL5UlJ0cWGCM7ABRbVFcbAS9vkLq7ias9ewKNA=s64",
      "userId": "03190496352220804755"
     },
     "user_tz": -480
    },
    "id": "djho9-rx3V6Z",
    "outputId": "a7e1e68a-8ce3-427f-8e11-a394c8826bc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-11-26--17-15-56\n",
      "torch.Size([2352])\n",
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "\n",
    "x = torch.rand(3,28,28) # given color image\n",
    "\n",
    "# YOUR CODE HERE\n",
    "x = x.view(-1); print(x.size())\n",
    "x = x.view(3,28,28); print(x.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5LNc-Fo7mT1"
   },
   "source": [
    "### Question 3\n",
    "\n",
    "Consider the score vector $s=[-1.2,4.5,2.3,-0.2]$ to be the output of a 4-class classification network. Convert the score vector $s$ into a probability vector with the softmax operator. Print the probabilities. \n",
    "\n",
    "Implement a Python function that returns the index of the class with the highest probability. Print the index of the highest probability for the above score vector $s$. Note that the 4 classes are indexed with integer values $\\{0,1,2,3\\}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1156,
     "status": "ok",
     "timestamp": 1600143105845,
     "user": {
      "displayName": "Vijay Prakash Dwivedi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgfLL5UlJ0cWGCM7ABRbVFcbAS9vkLq7ias9ewKNA=s64",
      "userId": "03190496352220804755"
     },
     "user_tz": -480
    },
    "id": "L67NCs9r7myO",
    "outputId": "ff9a3273-bb24-4cb8-e113-b26ec3bafeed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-11-26--17-17-51\n",
      "tensor([0.0030, 0.8903, 0.0986, 0.0081])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "\n",
    "s = torch.Tensor([-1.2,4.5,2.3,-0.2]) \n",
    "\n",
    "# YOUR CODE HERE\n",
    "prob = torch.nn.functional.softmax(s, dim=0)\n",
    "print(prob)\n",
    "\n",
    "def get_index(prob):\n",
    "    return torch.argmax(prob, dim=0)\n",
    "\n",
    "print(get_index(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Implement a Python function for the activation function $$\\sigma(x)=\\frac{2e^{x}-e^{-x}}{2e^{x}+e^{-x}}$$\n",
    "\n",
    "Print the activation values of the input tensor $x=[2.5,-1.2,0.0,-8.2]$ with function $\\sigma$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-11-26--17-19-52\n",
      "tensor([ 0.9933, -0.6929,  0.3333, -1.0000])\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "\n",
    "x = torch.Tensor([2.5,-1.2,0.0,-8.2])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "def sigma(x):\n",
    "    sig = (2*torch.exp(x) - torch.exp(-x))/(2*torch.exp(x) + torch.exp(-x))\n",
    "    return sig\n",
    "    \n",
    "print(sigma(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_dDEN-vne48"
   },
   "source": [
    "### Question 5\n",
    "\n",
    "Implement a PyTorch class for the following layer\n",
    "\n",
    "$$s = \\sigma(W x + b)$$\n",
    "\n",
    "with the non-linear activation function $\\sigma$ defined in Question 4. \n",
    "\n",
    "Print the output tensor $s$ of dimension 2 given the input tensor $x=[2.3,-1.4,3.9]$.\n",
    "\n",
    "Note that $W$ and $b$ can be any (random) tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 826,
     "status": "ok",
     "timestamp": 1600107092190,
     "user": {
      "displayName": "Vijay Prakash Dwivedi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgfLL5UlJ0cWGCM7ABRbVFcbAS9vkLq7ias9ewKNA=s64",
      "userId": "03190496352220804755"
     },
     "user_tz": -480
    },
    "id": "ZwCjd9Clgjnx",
    "outputId": "3a6d4b04-ab2d-49a9-94a6-6ec527548154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-11-26--17-22-46\n",
      "tensor([0.3452, 0.8968], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "\n",
    "x = torch.Tensor([2.3,-1.4,3.9])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "def sigma(x):\n",
    "    return (2*torch.exp(x) - torch.exp(-x))/(2*torch.exp(x) + torch.exp(-x))\n",
    "\n",
    "class one_layer_net(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = sigma(x)\n",
    "        return x\n",
    "    \n",
    "net = one_layer_net(3, 2)\n",
    "print(net(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Given a minibatch $s=[ [3.6,-1.1], [-2.1,6.0] ]$ of scores of 2 data points with 2 classes. Compute the mean cross entropy value for this minibatch with the labels $[0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-11-26--17-23-53\n",
      "0.004678829573094845\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "\n",
    "score = torch.Tensor([[3.6,-1.1], [-2.1,6.0]])\n",
    "label = torch.LongTensor([0,1])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(score, label)\n",
    "print(loss.detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jzJOcN45z-i1"
   },
   "source": [
    "### Question 7\n",
    "\n",
    "Implement a class of 3-layer MLP with the activation function of Question 4 such that\n",
    "\n",
    "$$s = W_3\\sigma(W_2\\sigma(W_1 x + b_1)+b_2)+b_3)$$\n",
    "\n",
    "Instantiate a network with 784 as input dimension, 25 as hidden dimension and 10 as output dimension. Print the network and the total number of parameters.\n",
    "\n",
    "Use 10 epochs to train the network with batch size 100 and learning rate 0.01. Print the loss and error of the training set after 10 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1044,
     "status": "ok",
     "timestamp": 1600148408449,
     "user": {
      "displayName": "Vijay Prakash Dwivedi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgfLL5UlJ0cWGCM7ABRbVFcbAS9vkLq7ias9ewKNA=s64",
      "userId": "03190496352220804755"
     },
     "user_tz": -480
    },
    "id": "YnPK0d0Igkkw",
    "outputId": "e00e737f-eda0-48e0-cd7e-68b2db4b5e28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-11-26--17-31-19\n",
      "three_layer_net(\n",
      "  (layer1): Linear(in_features=784, out_features=25, bias=True)\n",
      "  (layer2): Linear(in_features=25, out_features=25, bias=True)\n",
      "  (layer3): Linear(in_features=25, out_features=10, bias=True)\n",
      ")\n",
      "20535\n",
      "There are 20535 (0.02 million) parameters in this neural network\n",
      "epoch=10, time=8.035661, loss=0.310377, error=8.738333%, lr=0.010000\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from utils import *\n",
    "data_path=check_mnist_dataset_exists()\n",
    "train_data=torch.load(data_path+'mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'mnist/train_label.pt')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "def sigma(x):\n",
    "    return (2*torch.exp(x) - torch.exp(-x))/(2*torch.exp(x) + torch.exp(-x))\n",
    "\n",
    "class three_layer_net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2,  output_size):\n",
    "        super(three_layer_net , self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1, bias=True) \n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2, bias=True) \n",
    "        self.layer3 = nn.Linear(hidden_size2, output_size, bias=True)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y       = self.layer1(x) \n",
    "        y_hat   = sigma(y) \n",
    "        z       = self.layer2(y_hat) \n",
    "        z_hat   = sigma(z) \n",
    "        scores  = self.layer3(z_hat)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "net = three_layer_net(784, 25, 25, 10)\n",
    "print(net)\n",
    "print(sum(p.numel() for p in net.parameters() if p.requires_grad))\n",
    "utils.display_num_param(net)\n",
    "\n",
    "bs = 100\n",
    "my_lr = 0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "import time\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(10):\n",
    "    \n",
    "    # reset optimizer with new learning rate\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=my_lr)\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_error = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    shuffled_indices=torch.randperm(len(train_data)) # 60000\n",
    "    \n",
    "    for count in range(0, len(train_data), bs):\n",
    "        # reset gradients\n",
    "        optimizer.zero_grad() \n",
    "        # create minibatch\n",
    "        indices = shuffled_indices[count:count+bs]\n",
    "        minibatch_data = train_data[indices].to(device)   \n",
    "        minibatch_label = train_label[indices].to(device) \n",
    "        \n",
    "        inputs = minibatch_data.view(bs, 784) # reshape to fit network \n",
    "        # Start tracking all operations that will be done on \"inputs\"\n",
    "        inputs.requires_grad_()\n",
    "        \n",
    "        scores = net(inputs)\n",
    "        \n",
    "        loss = criterion(scores, minibatch_label) # compute CEL\n",
    "        loss.backward()  # compute gradients via backward pass\n",
    "        optimizer.step() # update weights using SGD\n",
    "        \n",
    "        running_loss += loss.detach().item()\n",
    "        error = utils.get_error(scores.detach(), minibatch_label)\n",
    "        running_error += error.detach().item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "print(f\"epoch={epoch+1}, time={elapsed:5f}, loss={total_loss:5f}, error={total_error*100:5f}%, lr={my_lr:5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Implement a class of 3-layer MLP with the ReLU activation function. Instantiate a network with 784 as input dimension, 7 as hidden dimension and 10 as output dimension. \n",
    "\n",
    "Use 20 epochs to train the network with batch size 100.\n",
    "\n",
    "Implement the following learning rate (lr) schedule. Start with an initial lr of 0.5. Reduce the lr value at each epoch by a factor of 2.0 (that is lr/2.0) if the error on the validation set does not decrease. Print the loss and the error of the training set, and the lr after 20 epochs. \n",
    "\n",
    "What is the error of the training set if the initial lr is 0.5 and no learning rate schedule is used? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-11-26--17-46-29\n",
      "Size of training set torch.Size([59000, 28, 28])\n",
      "Size of validation set torch.Size([1000, 28, 28])\n",
      "three_layer_net(\n",
      "  (layer1): Linear(in_features=784, out_features=7, bias=True)\n",
      "  (layer2): Linear(in_features=7, out_features=7, bias=True)\n",
      "  (layer3): Linear(in_features=7, out_features=10, bias=True)\n",
      ")\n",
      "5631\n",
      "There are 5631 (0.01 million) parameters in this neural network\n",
      "With LR Scheduler: \n",
      "epoch=1, time=0.566378, loss=1.198555, error=50.322034%, lr=0.500000\n",
      "=> test error: 41.600001 %\n",
      "epoch=2, time=1.049273, loss=0.925965, error=38.688136%, lr=0.500000\n",
      "=> test error: 30.200000 %\n",
      "epoch=3, time=1.525797, loss=0.773893, error=30.515254%, lr=0.500000\n",
      "=> test error: 27.300000 %\n",
      "epoch=4, time=2.030067, loss=0.706061, error=26.961017%, lr=0.500000\n",
      "=> test error: 22.400000 %\n",
      "epoch=5, time=2.530285, loss=0.651028, error=24.240678%, lr=0.500000\n",
      "=> test error: 22.100000 %\n",
      "epoch=6, time=3.051214, loss=0.630401, error=22.913560%, lr=0.500000\n",
      "=> test error: 21.400000 %\n",
      "epoch=7, time=3.527211, loss=0.604822, error=21.861017%, lr=0.500000\n",
      "=> test error: 19.600001 %\n",
      "epoch=8, time=4.025258, loss=0.602458, error=21.486441%, lr=0.500000\n",
      "=> test error: 19.700001 %\n",
      "reducing\n",
      "epoch=9, time=4.498842, loss=0.529611, error=18.964407%, lr=0.250000\n",
      "=> test error: 20.100000 %\n",
      "reducing\n",
      "epoch=10, time=5.009661, loss=0.498659, error=17.877966%, lr=0.125000\n",
      "=> test error: 18.899999 %\n",
      "epoch=11, time=5.512650, loss=0.486341, error=17.045763%, lr=0.125000\n",
      "=> test error: 17.600001 %\n",
      "epoch=12, time=6.027436, loss=0.476605, error=16.628814%, lr=0.125000\n",
      "=> test error: 18.200001 %\n",
      "reducing\n",
      "epoch=13, time=6.526936, loss=0.462925, error=16.115254%, lr=0.062500\n",
      "=> test error: 16.800000 %\n",
      "epoch=14, time=7.029662, loss=0.459322, error=16.003390%, lr=0.062500\n",
      "=> test error: 16.400001 %\n",
      "epoch=15, time=7.634389, loss=0.457642, error=15.915254%, lr=0.062500\n",
      "=> test error: 15.600000 %\n",
      "epoch=16, time=8.290806, loss=0.455684, error=15.832203%, lr=0.062500\n",
      "=> test error: 16.800001 %\n",
      "reducing\n",
      "epoch=17, time=8.877504, loss=0.449679, error=15.615254%, lr=0.031250\n",
      "=> test error: 15.600001 %\n",
      "epoch=18, time=9.506404, loss=0.448538, error=15.557627%, lr=0.031250\n",
      "=> test error: 16.000001 %\n",
      "reducing\n",
      "epoch=19, time=10.075725, loss=0.445714, error=15.545763%, lr=0.015625\n",
      "=> test error: 15.400000 %\n",
      "epoch=20, time=10.610790, loss=0.445106, error=15.472882%, lr=0.015625\n",
      "=> test error: 15.800000 %\n",
      "reducing\n",
      "epoch=20, time=10.610790, loss=0.445106, error=15.472882%, val_error=15.800000%, lr=0.007812\n",
      "\n",
      "Without LR Scheduler: \n",
      "epoch=1, time=0.527308, loss=1.470037, error=62.352542%, lr=0.500000\n",
      "=> test error: 49.200000 %\n",
      "epoch=2, time=1.068877, loss=1.345032, error=58.177966%, lr=0.500000\n",
      "=> test error: 79.400001 %\n",
      "epoch=3, time=1.572869, loss=1.274159, error=55.206780%, lr=0.500000\n",
      "=> test error: 40.599999 %\n",
      "epoch=4, time=2.083562, loss=1.220702, error=52.386441%, lr=0.500000\n",
      "=> test error: 69.599999 %\n",
      "epoch=5, time=2.621834, loss=1.542152, error=68.922034%, lr=0.500000\n",
      "=> test error: 69.900001 %\n",
      "epoch=6, time=3.133734, loss=1.733908, error=79.113560%, lr=0.500000\n",
      "=> test error: 80.500001 %\n",
      "epoch=7, time=3.646145, loss=1.685581, error=80.125424%, lr=0.500000\n",
      "=> test error: 81.000000 %\n",
      "epoch=8, time=4.149117, loss=1.679924, error=79.952543%, lr=0.500000\n",
      "=> test error: 78.299999 %\n",
      "epoch=9, time=4.666752, loss=1.674724, error=79.979661%, lr=0.500000\n",
      "=> test error: 79.500001 %\n",
      "epoch=10, time=5.194001, loss=1.832943, error=79.983051%, lr=0.500000\n",
      "=> test error: 78.300000 %\n",
      "epoch=11, time=5.711028, loss=1.727550, error=80.159322%, lr=0.500000\n",
      "=> test error: 78.900000 %\n",
      "epoch=12, time=6.215802, loss=1.710153, error=80.237288%, lr=0.500000\n",
      "=> test error: 81.500000 %\n",
      "epoch=13, time=6.748773, loss=1.698656, error=80.376271%, lr=0.500000\n",
      "=> test error: 82.500000 %\n",
      "epoch=14, time=7.273914, loss=1.715206, error=80.111864%, lr=0.500000\n",
      "=> test error: 78.800001 %\n",
      "epoch=15, time=7.774108, loss=1.698043, error=80.300000%, lr=0.500000\n",
      "=> test error: 78.199999 %\n",
      "epoch=16, time=8.268863, loss=1.704464, error=80.205085%, lr=0.500000\n",
      "=> test error: 81.000000 %\n",
      "epoch=17, time=8.742076, loss=1.695941, error=79.908475%, lr=0.500000\n",
      "=> test error: 79.199999 %\n",
      "epoch=18, time=9.231262, loss=1.695156, error=80.203390%, lr=0.500000\n",
      "=> test error: 80.199999 %\n",
      "epoch=19, time=9.716670, loss=1.687772, error=80.198305%, lr=0.500000\n",
      "=> test error: 80.900001 %\n",
      "epoch=20, time=10.171858, loss=1.689407, error=80.389831%, lr=0.500000\n",
      "=> test error: 80.600001 %\n",
      "epoch=20, time=10.171858, loss=1.689407, error=80.389831%, val_error=80.600001%, lr=0.500000\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from utils import *\n",
    "data_path=check_fashion_mnist_dataset_exists()\n",
    "train_data=torch.load(data_path+'fashion-mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'fashion-mnist/train_label.pt')\n",
    "idx = torch.arange(60000)\n",
    "idx_train = idx[:59000]\n",
    "idx_val = idx[59000:]\n",
    "val_data = train_data[idx_val]\n",
    "val_label = train_label[idx_val]\n",
    "train_data = train_data[idx_train]\n",
    "train_label = train_label[idx_train]\n",
    "\n",
    "print('Size of training set',train_data.size())\n",
    "print('Size of validation set',val_data.size())\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "class three_layer_net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2,  output_size):\n",
    "        super(three_layer_net , self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1, bias=True) \n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2, bias=True) \n",
    "        self.layer3 = nn.Linear(hidden_size2, output_size, bias=True)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y       = self.layer1(x) \n",
    "        y_hat   = torch.nn.functional.relu(y) \n",
    "        z       = self.layer2(y_hat) \n",
    "        z_hat   = torch.nn.functional.relu(z) \n",
    "        scores  = self.layer3(z_hat)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "net = three_layer_net(784, 7, 7, 10)\n",
    "print(net)\n",
    "print(sum(p.numel() for p in net.parameters() if p.requires_grad))\n",
    "utils.display_num_param(net)\n",
    "\n",
    "import time\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "def eval_on_test_set(bs):\n",
    "    running_error = 0\n",
    "    num_batches = 0\n",
    "    for i in range(0, len(val_data), bs):\n",
    "        minibatch_data = val_data[i:i+bs].to(device)\n",
    "        minibatch_label = val_label[i:i+bs].to(device)\n",
    "        inputs = minibatch_data.view(bs, 784)\n",
    "        scores = net(inputs)\n",
    "        error = utils.get_error(scores, minibatch_label)\n",
    "        running_error += error.detach().item()\n",
    "        num_batches += 1\n",
    "    total_error = running_error / num_batches\n",
    "    print(f\"=> test error: {total_error*100:5f} %\")\n",
    "    return total_error\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "def trainer(lr_schedule=True):    \n",
    "    bs = 100\n",
    "    my_lr = 0.5\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    prev_val = None\n",
    "    start = time.time()\n",
    "    for epoch in range(20):\n",
    "\n",
    "        # reset optimizer with new learning rate\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=my_lr)\n",
    "\n",
    "        running_loss = 0\n",
    "        running_error = 0\n",
    "        num_batches = 0\n",
    "    \n",
    "        shuffled_indices=torch.randperm(len(train_data)) # 60000\n",
    "\n",
    "        for count in range(0, len(train_data), bs):\n",
    "            # reset gradients\n",
    "            optimizer.zero_grad() \n",
    "            # create minibatch\n",
    "            indices = shuffled_indices[count:count+bs]\n",
    "            minibatch_data = train_data[indices].to(device)   \n",
    "            minibatch_label = train_label[indices].to(device) \n",
    "\n",
    "            inputs = minibatch_data.view(bs, 784) # reshape to fit network \n",
    "            # Start tracking all operations that will be done on \"inputs\"\n",
    "            inputs.requires_grad_()\n",
    "\n",
    "            scores = net(inputs)\n",
    "\n",
    "            loss = criterion(scores, minibatch_label) # compute CEL\n",
    "            loss.backward()  # compute gradients via backward pass\n",
    "            optimizer.step() # update weights using SGD\n",
    "\n",
    "            running_loss += loss.detach().item()\n",
    "            error = utils.get_error(scores.detach(), minibatch_label)\n",
    "            running_error += error.detach().item()\n",
    "            num_batches += 1\n",
    "\n",
    "        total_loss = running_loss/num_batches\n",
    "        total_error = running_error/num_batches\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"epoch={epoch+1}, time={elapsed:5f}, loss={total_loss:5f}, error={total_error*100:5f}%, lr={my_lr:5f}\")\n",
    "        val_error = eval_on_test_set(bs)\n",
    "        \n",
    "        #set_trace()\n",
    "        if lr_schedule and prev_val and val_error >= prev_val:\n",
    "            print(\"reducing\")\n",
    "            my_lr = my_lr/2.0\n",
    "        prev_val = val_error\n",
    "        \n",
    "    print(f\"epoch={epoch+1}, time={elapsed:5f}, loss={total_loss:5f}, error={total_error*100:5f}%, val_error={val_error*100:5f}%, lr={my_lr:5f}\")     \n",
    "\n",
    "print(f\"With LR Scheduler: \")\n",
    "trainer(True)\n",
    "net = three_layer_net(784, 7, 7, 10)\n",
    "print(\"\")\n",
    "print(f\"Without LR Scheduler: \")\n",
    "trainer(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Implement a class of 3-layer MLP with the ReLU activation function. Instantiate a network with 784 as input dimension, 25 as hidden dimension and 1 as output dimension. \n",
    "\n",
    "The output dimension is 1 because the problem is changed from a classification task to a regression task. The regression task consists in predicting the class index, here the values 0,1,2,3,...,9 for the ten classes of FASHION-MNIST.\n",
    "\n",
    "Implement the standard regression loss\n",
    "\n",
    "$$ L = \\frac{1}{n}\\sqrt{\\sum_{i=1}^n (s_i - \\textrm{cl}(i))^2}$$\n",
    "\n",
    "where $s_i=\\textrm{3-layer MLP}(x_i)$ is the output of the 3-layer MLP and $\\textrm{cl}(i)$ is the class index of data point $x_i$.\n",
    "\n",
    "Use 10 epochs to train the network with batch size 100 and learning rate 0.001. Print the loss of the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-11-26--17-54-51\n",
      "three_layer_net(\n",
      "  (layer1): Linear(in_features=784, out_features=25, bias=True)\n",
      "  (layer2): Linear(in_features=25, out_features=25, bias=True)\n",
      "  (layer3): Linear(in_features=25, out_features=1, bias=True)\n",
      ")\n",
      "There are 20301 (0.02 million) parameters in this neural network\n",
      "epoch=10, time=5.451626, loss=0.224843, lr=0.001000\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from utils import *\n",
    "data_path=check_fashion_mnist_dataset_exists()\n",
    "train_data=torch.load(data_path+'fashion-mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'fashion-mnist/train_label.pt')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "class three_layer_net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2,  output_size):\n",
    "        super(three_layer_net , self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1, bias=True) \n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2, bias=True) \n",
    "        self.layer3 = nn.Linear(hidden_size2, output_size, bias=True)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y       = self.layer1(x) \n",
    "        y_hat   = torch.nn.functional.relu(y) \n",
    "        z       = self.layer2(y_hat) \n",
    "        z_hat   = torch.nn.functional.relu(z) \n",
    "        scores  = self.layer3(z_hat)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "net = three_layer_net(784, 25, 25, 1)\n",
    "print(net)\n",
    "utils.display_num_param(net)\n",
    "\n",
    "bs = 100\n",
    "my_lr = 0.001 \n",
    "\n",
    "def regression_loss(scores, labels, bs):\n",
    "    return ( ( scores.squeeze() - minibatch_label.float() )**2 ).sum().sqrt()/ bs\n",
    "\n",
    "import time\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(10):\n",
    "    \n",
    "    # reset optimizer with new learning rate\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=my_lr)\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_error = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    shuffled_indices=torch.randperm(len(train_data)) # 60000\n",
    "    \n",
    "    for count in range(0, len(train_data), bs):\n",
    "        # reset gradients\n",
    "        optimizer.zero_grad() \n",
    "        # create minibatch\n",
    "        indices = shuffled_indices[count:count+bs]\n",
    "        minibatch_data = train_data[indices].to(device)   \n",
    "        minibatch_label = train_label[indices].to(device) \n",
    "        \n",
    "        inputs = minibatch_data.view(bs, 784) # reshape to fit network \n",
    "        # Start tracking all operations that will be done on \"inputs\"\n",
    "        inputs.requires_grad_()\n",
    "        \n",
    "        scores = net(inputs)\n",
    "        \n",
    "        loss = regression_loss(scores, minibatch_label, bs) # compute CEL\n",
    "        loss.backward()  # compute gradients via backward pass\n",
    "        optimizer.step() # update weights using SGD\n",
    "        \n",
    "        running_loss += loss.detach().item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    total_loss = running_loss/num_batches\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "print(f\"epoch={epoch+1}, time={elapsed:5f}, loss={total_loss:5f}, lr={my_lr:5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Implement a class of 1-layer MLP, that is $$s=Wx+b$$ \n",
    "\n",
    "with no activation function. Instantiate a network with 784 as input dimension and 2 as output dimension. \n",
    "\n",
    "The output dimension is 2 because the task is to classify digits 1s and 7s with 6,000 training data for the class 1 and 600 training data for the class of 7. This classification task is unbalanced. \n",
    "\n",
    "To correct the unbalanced training set, a weighted cross entropy loss is used and defined as\n",
    "\n",
    "$$ L = -\\frac{1}{N}\\sum_{i=1}^N w^{(i)}. \\log \\Big(\\textrm{entry cl($i$) of probability vector } p^{(i)} \\Big)$$\n",
    "\n",
    "where $cl($i$)$ is the class index of the $i^{th}$ training data, $p^{(i)}$ is the probability vector computed by the network, and $w^{(i)}$ is equal to $0.1$ for data belonging to the class of 1s and $w^{(i)}$ equal to $1.0$ for data belonging to the class of 7s.\n",
    "\n",
    "Implement the weighted cross entropy loss. Use 20 epochs to train the network with batch size 100 and learning rate 0.01. Print the weighted cross entropy loss and error value for the training set. Print the error value for the test set.\n",
    "\n",
    "Compute and compare theses values with the standard non-weighted cross entropy loss defined as\n",
    "\n",
    "$$ L = -\\frac{1}{N}\\sum_{i=1}^N \\log \\Big(\\textrm{entry cl($i$) of probability vector } p^{(i)} \\Big)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-11-26--17-56-35\n",
      "Size of training set: torch.Size([6600, 28, 28])\n",
      "Size of test set: torch.Size([200, 28, 28])\n",
      "epoch= 0  loss= 0.08878127254094138  train_error= 9.924242261684302  test_error= 0.0\n",
      "epoch= 1  loss= 0.06297045353461396  train_error= 9.090909000599023  test_error= 0.0\n",
      "epoch= 2  loss= 0.06116464361548424  train_error= 9.090908819978887  test_error= 0.0\n",
      "epoch= 3  loss= 0.05978196108657302  train_error= 9.090909000599023  test_error= 0.0\n",
      "epoch= 4  loss= 0.058504496842171204  train_error= 9.090908910288956  test_error= 0.0\n",
      "epoch= 5  loss= 0.057303987528112804  train_error= 9.090908910288956  test_error= 0.0\n",
      "epoch= 6  loss= 0.056168906108448  train_error= 9.090909090909092  test_error= 0.0\n",
      "epoch= 7  loss= 0.05512016540336789  train_error= 9.090908910288956  test_error= 0.0\n",
      "epoch= 8  loss= 0.05413526025685397  train_error= 9.106060681921063  test_error= 0.0\n",
      "epoch= 9  loss= 0.05321478778778604  train_error= 9.106060681921063  test_error= 0.0\n",
      "epoch= 10  loss= 0.05236453678684704  train_error= 9.10606041099086  test_error= 0.0\n",
      "epoch= 11  loss= 0.05157404336513895  train_error= 9.121211821382696  test_error= 0.0\n",
      "epoch= 12  loss= 0.05084357605400411  train_error= 9.121212182622967  test_error= 0.0\n",
      "epoch= 13  loss= 0.050155605528165  train_error= 9.121211821382696  test_error= 0.0\n",
      "epoch= 14  loss= 0.04954286207529632  train_error= 9.136363683324872  test_error= 0.0\n",
      "epoch= 15  loss= 0.048964828196348564  train_error= 9.136363412394669  test_error= 0.0\n",
      "epoch= 16  loss= 0.04841692610220476  train_error= 9.136363231774533  test_error= 0.0\n",
      "epoch= 17  loss= 0.0479164853353392  train_error= 9.136363412394669  test_error= 0.0\n",
      "epoch= 18  loss= 0.04744992678928556  train_error= 9.136363141464464  test_error= 0.0\n",
      "epoch= 19  loss= 0.047013912716823994  train_error= 9.136363502704736  test_error= 0.0\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "from packaging import version\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from utils import *\n",
    "data_path=check_fashion_mnist_dataset_exists()\n",
    "train_data=torch.load(data_path+'fashion-mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'fashion-mnist/train_label.pt')\n",
    "test_data=torch.load(data_path+'fashion-mnist/test_data.pt')\n",
    "test_label=torch.load(data_path+'fashion-mnist/test_label.pt')\n",
    "\n",
    "if version.parse(torch.__version__) < version.parse(\"1.6.0\"):\n",
    "    idx_class0 = (train_label==1-1).nonzero().squeeze()\n",
    "    idx_class1 = (train_label==7-1).nonzero().squeeze()\n",
    "else:\n",
    "    idx_class0 = (train_label==1-1).nonzero(as_tuple=False).squeeze()\n",
    "    idx_class1 = (train_label==7-1).nonzero(as_tuple=False).squeeze()\n",
    "idx_class0 = idx_class0[:6000]\n",
    "idx_class1 = idx_class1[:600]\n",
    "train_data = train_data[torch.cat((idx_class0,idx_class1))]\n",
    "train_label = train_label[torch.cat((idx_class0,idx_class1))]\n",
    "train_label[train_label==1-1] = 0 # class 1 has label 0\n",
    "train_label[train_label==7-1] = 1 # class 7 has label 1\n",
    "\n",
    "if version.parse(torch.__version__) < version.parse(\"1.6.0\"):\n",
    "    idx_class0 = (test_label==1-1).nonzero().squeeze()\n",
    "    idx_class1 = (test_label==7-1).nonzero().squeeze()\n",
    "else:\n",
    "    idx_class0 = (test_label==1-1).nonzero(as_tuple=False).squeeze()\n",
    "    idx_class1 = (test_label==7-1).nonzero(as_tuple=False).squeeze() \n",
    "idx_class0 = idx_class0[:6000]\n",
    "idx_class1 = idx_class1[:600]\n",
    "test_data = test_data[torch.cat((idx_class0,idx_class1))]\n",
    "test_label = test_label[torch.cat((idx_class0,idx_class1))]\n",
    "test_label[test_label==1-1] = 0 # class 1 has label 0\n",
    "test_label[test_label==7-1] = 1 # class 7 has label 1\n",
    "test_data = test_data[:200]\n",
    "test_label = test_label[:200]\n",
    "\n",
    "print('Size of training set:',train_data.size())\n",
    "print('Size of test set:',test_data.size())\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "class one_layer_MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(one_layer_MLP , self).__init__()\n",
    "        self.layer = nn.Linear(  input_size, output_size )\n",
    "    def forward(self, x):\n",
    "        score = self.layer(x)\n",
    "        return score\n",
    "\n",
    "net = one_layer_MLP(784,2)\n",
    "bs = 100\n",
    "optimizer=torch.optim.SGD( net.parameters() , lr=0.01 )\n",
    "\n",
    "for epoch in range(20):\n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    shuffled_indices=torch.randperm(train_data.size(0))            \n",
    "    for count in range(0,train_data.size(0),bs):\n",
    "        optimizer.zero_grad()\n",
    "        indices = shuffled_indices[count:count+bs]\n",
    "        minibatch_data = train_data[indices]\n",
    "        minibatch_label = train_label[indices]\n",
    "        inputs = minibatch_data.view(bs,784)\n",
    "        inputs.requires_grad_()\n",
    "        scores = net( inputs ) \n",
    "        \n",
    "        # weighted cross entropy\n",
    "        p = torch.softmax(scores, dim=1)\n",
    "        log_prob = -torch.log(p)\n",
    "        w = torch.zeros(bs)\n",
    "        w[minibatch_label==0] = 1\n",
    "        w[minibatch_label==1] = 1/10\n",
    "        loss = (w* log_prob[torch.arange(bs),minibatch_label]).mean() # weighted cross entropy\n",
    "        #loss = log_prob[torch.arange(bs),minibatch_label].mean() # un-weighted cross entropy\n",
    "        error = get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.detach().item()\n",
    "        num_batches+=1\n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    \n",
    "    # test error\n",
    "    scores = net( test_data.view(200,784) ) \n",
    "    test_error = get_error( scores.detach() , test_label).item()\n",
    "           \n",
    "    print('epoch=',epoch, ' loss=', total_loss, ' train_error=', 100*total_error, ' test_error=', 100*test_error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNd30TjgREYWyAkV0lT4iX6",
   "name": "CE_7454_coding_test_solution_Vijay.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
