{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01 : Convolutional layer - demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a convolutional module\n",
    "* inputs:  2 channels\n",
    "* output:  5 activation maps \n",
    "* filters are 3x3\n",
    "* padding with one layer of zero to not shrink anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = nn.Conv2d( 2 , 5 ,  kernel_size=3,  padding=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an input 2 x 6 x 6  (two channels, each one has 6 x 6 pixels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.1547, 0.7232, 0.6395, 0.5490, 0.7109, 0.4869],\n",
      "          [0.4964, 0.5220, 0.1526, 0.6450, 0.9332, 0.9990],\n",
      "          [0.5541, 0.4980, 0.8310, 0.1912, 0.4766, 0.9040],\n",
      "          [0.2206, 0.8510, 0.5701, 0.0375, 0.3505, 0.2003],\n",
      "          [0.4629, 0.4703, 0.2831, 0.4072, 0.9618, 0.0384],\n",
      "          [0.4350, 0.4967, 0.9412, 0.7495, 0.0094, 0.4609]],\n",
      "\n",
      "         [[0.8039, 0.9302, 0.7381, 0.5219, 0.1925, 0.9237],\n",
      "          [0.5447, 0.4008, 0.4000, 0.5659, 0.2255, 0.1632],\n",
      "          [0.3571, 0.1388, 0.5516, 0.6121, 0.1035, 0.9965],\n",
      "          [0.5659, 0.7911, 0.2385, 0.9609, 0.2500, 0.9127],\n",
      "          [0.0458, 0.7271, 0.8613, 0.8330, 0.9604, 0.3535],\n",
      "          [0.9272, 0.1359, 0.2476, 0.2435, 0.5452, 0.2271]]]])\n",
      "torch.Size([1, 2, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "bs=1\n",
    "\n",
    "x=torch.rand(bs,2,6,6)\n",
    "\n",
    "print(x)\n",
    "\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed it to the convolutional layer: the output should have 5 channels (each one is 6x6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-4.3936e-01, -4.3251e-01, -3.3035e-01, -3.6198e-01, -1.6227e-01,\n",
      "           -4.9804e-01],\n",
      "          [-1.0225e-01,  1.0078e-01, -3.8880e-01, -9.5737e-02, -2.8944e-01,\n",
      "           -2.4081e-01],\n",
      "          [-4.5096e-02, -3.7237e-01, -4.8169e-01, -1.9167e-01, -3.3863e-01,\n",
      "           -2.9129e-01],\n",
      "          [-2.4978e-01, -2.9351e-01, -2.8328e-01, -6.7976e-01, -3.2800e-01,\n",
      "           -2.7658e-01],\n",
      "          [-1.3160e-02, -5.7918e-02, -3.1476e-01, -4.3242e-01,  6.2473e-02,\n",
      "           -4.4910e-01],\n",
      "          [-2.1668e-01, -1.1719e-01, -3.9752e-02,  7.7661e-02, -1.7342e-01,\n",
      "           -1.1002e-01]],\n",
      "\n",
      "         [[-3.8525e-01, -5.8206e-01, -4.2810e-01, -3.9528e-01, -4.3835e-01,\n",
      "           -3.2070e-01],\n",
      "          [-4.6603e-01, -4.7566e-01, -6.3022e-01, -5.2220e-01, -5.3812e-01,\n",
      "           -3.0897e-01],\n",
      "          [-1.2078e-01, -6.1115e-01, -5.0295e-01, -5.0360e-01, -8.7602e-01,\n",
      "           -3.9994e-01],\n",
      "          [-4.5242e-01, -4.0612e-01, -6.7816e-01, -4.6114e-01, -8.8006e-01,\n",
      "           -5.7843e-01],\n",
      "          [-4.1411e-01, -6.6887e-01, -7.5868e-01, -7.7220e-01, -4.1940e-01,\n",
      "           -6.8852e-01],\n",
      "          [-4.9886e-01, -7.6358e-01, -5.3983e-01, -6.4364e-01, -6.4749e-01,\n",
      "           -3.1966e-01]],\n",
      "\n",
      "         [[ 2.6462e-02,  1.0923e-01,  2.1446e-01,  3.4512e-02,  3.0405e-02,\n",
      "            1.3386e-03],\n",
      "          [-1.1958e-01,  9.4426e-02,  1.3924e-01,  9.8939e-02,  1.7255e-02,\n",
      "            1.7068e-01],\n",
      "          [-7.5135e-02, -1.3828e-04,  1.0038e-01,  3.0811e-02,  4.2374e-02,\n",
      "           -2.3179e-02],\n",
      "          [ 1.3533e-02, -2.7557e-02, -1.6661e-03,  5.5428e-02, -3.1618e-01,\n",
      "           -3.1959e-03],\n",
      "          [-1.8733e-01,  7.5298e-03, -1.6799e-02,  2.9861e-01,  1.7159e-01,\n",
      "            2.7111e-01],\n",
      "          [-1.1239e-01,  1.7648e-01,  3.8993e-01,  3.3640e-01,  3.3851e-01,\n",
      "            4.3586e-01]],\n",
      "\n",
      "         [[ 7.5989e-02,  4.9147e-03,  1.8966e-01,  2.1180e-01,  4.5597e-01,\n",
      "            1.5251e-01],\n",
      "          [-1.4958e-02,  3.1126e-01,  6.6246e-02,  1.3854e-01,  1.7219e-01,\n",
      "            1.4302e-01],\n",
      "          [-3.4480e-03,  3.1588e-01,  1.5677e-01,  2.0790e-01,  8.0723e-02,\n",
      "            1.7403e-01],\n",
      "          [-1.1226e-01, -1.0013e-01,  3.9162e-01,  1.6510e-01,  3.2831e-01,\n",
      "            1.0607e-01],\n",
      "          [ 1.9924e-01,  4.8178e-01,  3.0675e-01, -2.9754e-01,  4.6173e-01,\n",
      "            5.8760e-02],\n",
      "          [-1.3780e-02, -1.6503e-01,  8.7035e-02,  3.9163e-01,  1.4282e-01,\n",
      "            4.5254e-02]],\n",
      "\n",
      "         [[-1.2854e-01,  1.5467e-01,  1.6841e-01, -1.0845e-02, -1.4491e-01,\n",
      "            3.2945e-01],\n",
      "          [-1.1031e-01,  2.0921e-02,  6.7227e-02, -1.3833e-01, -1.3629e-01,\n",
      "            3.5989e-01],\n",
      "          [-1.2263e-01, -1.1380e-01,  1.6114e-01,  9.9421e-02, -4.3125e-01,\n",
      "            2.1943e-01],\n",
      "          [-3.0187e-01,  2.2856e-01,  1.7002e-01, -4.8296e-02,  8.9450e-02,\n",
      "            2.7219e-02],\n",
      "          [-1.6285e-01, -3.2569e-01,  8.5619e-02,  1.6135e-01,  4.5754e-01,\n",
      "            1.2014e-01],\n",
      "          [-9.3805e-02, -8.4721e-02, -2.6299e-02,  5.7146e-02, -5.5637e-02,\n",
      "           -3.2691e-03]]]], grad_fn=<MkldnnConvolutionBackward>)\n",
      "torch.Size([1, 5, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "y=mod(x)\n",
    "\n",
    "print(y)\n",
    "\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets look at the 5 filters.\n",
    "* Our filters are 2x3x3\n",
    "* Each of the filter has 2 channels because the inputs have two channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.1534,  0.1850,  0.0978],\n",
      "          [-0.1809,  0.2348, -0.1412],\n",
      "          [ 0.1115, -0.1740,  0.2325]],\n",
      "\n",
      "         [[ 0.0765,  0.1219, -0.0364],\n",
      "          [ 0.0858, -0.1842,  0.0661],\n",
      "          [-0.2204, -0.0799, -0.2018]]],\n",
      "\n",
      "\n",
      "        [[[-0.0967, -0.0970, -0.0841],\n",
      "          [-0.1011,  0.1072, -0.1323],\n",
      "          [ 0.1198, -0.0672,  0.1519]],\n",
      "\n",
      "         [[ 0.0293, -0.0385, -0.1278],\n",
      "          [-0.1823, -0.1214, -0.2138],\n",
      "          [-0.2269,  0.0714,  0.1606]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0225, -0.1798, -0.0949],\n",
      "          [ 0.1458,  0.1238,  0.0611],\n",
      "          [-0.0238, -0.1559, -0.0787]],\n",
      "\n",
      "         [[ 0.2260,  0.1684, -0.1894],\n",
      "          [ 0.0525, -0.0090,  0.0745],\n",
      "          [-0.1152, -0.1227,  0.0671]]],\n",
      "\n",
      "\n",
      "        [[[-0.1203,  0.0469, -0.0565],\n",
      "          [ 0.2083,  0.0224, -0.1875],\n",
      "          [ 0.0605, -0.0856,  0.2080]],\n",
      "\n",
      "         [[ 0.2119, -0.1842,  0.0861],\n",
      "          [-0.1352, -0.1210,  0.1675],\n",
      "          [ 0.1587,  0.0913, -0.1896]]],\n",
      "\n",
      "\n",
      "        [[[-0.0906, -0.0946, -0.1405],\n",
      "          [ 0.1228,  0.1425, -0.1598],\n",
      "          [ 0.1312,  0.0562, -0.1920]],\n",
      "\n",
      "         [[ 0.0733,  0.0380,  0.0939],\n",
      "          [ 0.1442,  0.1667, -0.0846],\n",
      "          [-0.1717,  0.1893,  0.1462]]]], requires_grad=True)\n",
      "torch.Size([5, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(mod.weight)\n",
    "\n",
    "print(mod.weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
