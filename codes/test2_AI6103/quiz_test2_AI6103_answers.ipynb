{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JhPXB9mng7Py"
   },
   "source": [
    "\n",
    "## AI6103 : Deep Learning and Applications\n",
    "##Â Xavier Bresson\n",
    "\n",
    "\n",
    "## Quiz\n",
    "Date: October 22nd, 2020<br>\n",
    "\n",
    "*Instructions* <br>\n",
    "Name: Do not forget to add your name to the notebook file \"quiz_test2_AI6103_YOUR_NAME.ipynb\".<br>\n",
    "Questions: This notebook has 10 questions.<br>\n",
    "Answers: Write the answers to each question in this notebook.<br>\n",
    "Recommendation: Write concise and to-the-point answers.<br>\n",
    "Type: This test is individual and open-book.<br>\n",
    "Grading: 1 point for each question.<br>\n",
    "LaTeX: If you want to write mathematical equations, you are free to use LaTeX or not. <br>\n",
    "Output/Timestamp: There is no point if the cell has no output or the timestamp is beyond **9:30pm**.<br>\n",
    "Delivery: Upload your notebook to https://drive.google.com/drive/folders/1fJDoiA4hav9gv-1BlfF-kw1h1I47cewi **9:35pm**. <br>\n",
    "Remark: **If certain conditions of the questions (for eg. choice of activation function) are not stated, you are free to choose anything you want.**<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is an epoch? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-21--10-18-02\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    \n",
       "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
       "\n",
       "**YOUR ANSWER HERE**\n",
       "\n",
       "An epoch is a full pass over all training data once and only once.\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "Markdown(\"\"\"\n",
    "    \n",
    "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
    "\n",
    "**YOUR ANSWER HERE**\n",
    "\n",
    "An epoch is a full pass over all training data once and only once.\n",
    "    \n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What is the learning rate?\n",
    "\n",
    "How to select its value?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-21--10-18-02\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    \n",
       "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
       "\n",
       "**YOUR ANSWER HERE**\n",
       "\n",
       "The learning rate controls the speed of the gradient descent algorithm.\n",
       "\n",
       "Its value is selected to be large at the beginning of the process and then \n",
       "smaller when moving closer to the minimum of the loss landscape.\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "Markdown(\"\"\"\n",
    "    \n",
    "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
    "\n",
    "**YOUR ANSWER HERE**\n",
    "\n",
    "The learning rate controls the speed of the gradient descent algorithm.\n",
    "\n",
    "Its value is selected to be large at the beginning of the process and then \n",
    "smaller when moving closer to the minimum of the loss landscape.\n",
    "    \n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What is the advantage of using mini-batch training over full-batch training?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-21--10-18-02\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    \n",
       "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
       "\n",
       "**YOUR ANSWER HERE**\n",
       "\n",
       "Advantage of mini-batch over full-batch : Faster weight updates and better generalization performance.\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "Markdown(\"\"\"\n",
    "    \n",
    "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
    "\n",
    "**YOUR ANSWER HERE**\n",
    "\n",
    "Advantage of mini-batch over full-batch : Faster weight updates and better generalization performance.\n",
    "    \n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What is overfitting?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-21--10-18-02\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    \n",
       "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
       "\n",
       "**YOUR ANSWER HERE**\n",
       "\n",
       "Overfitting happens when the loss/error value is zero on the training data.\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "Markdown(\"\"\"\n",
    "    \n",
    "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
    "\n",
    "**YOUR ANSWER HERE**\n",
    "\n",
    "Overfitting happens when the loss/error value is zero on the training data.\n",
    "    \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "What is the vanishing gradient problem? \n",
    "\n",
    "How does the ReLU activation function help to solve this problem?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-21--10-18-02\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    \n",
       "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
       "\n",
       "**YOUR ANSWER HERE**\n",
       "\n",
       "Vanishing gradient problem happens when the gradient of the loss function approaches or is equal to zero, \n",
       "stopping the training of the network. \n",
       "\n",
       "Activation functions, like sigmoid or tanh, have derivative close or equal to zero for large positive \n",
       "or negative values. As such, they suffer from vanishing gradient.\n",
       "\n",
       "The ReLU activation function does not suffer from the vanishing gradient \n",
       "as the gradient value is always one for the positive values.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "Markdown(\"\"\"\n",
    "    \n",
    "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
    "\n",
    "**YOUR ANSWER HERE**\n",
    "\n",
    "Vanishing gradient problem happens when the gradient of the loss function approaches or is equal to zero, \n",
    "stopping the training of the network. \n",
    "\n",
    "Activation functions, like sigmoid or tanh, have derivative close or equal to zero for large positive \n",
    "or negative values. As such, they suffer from vanishing gradient.\n",
    "\n",
    "The ReLU activation function does not suffer from the vanishing gradient \n",
    "as the gradient value is always one for the positive values.\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 \n",
    "\n",
    "What is the main difference between multi-layer perceptrons (MLP) and convolutional neural networks (CNNs) in terms of pattern matching?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-21--10-18-02\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    \n",
       "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
       "\n",
       "**YOUR ANSWER HERE**\n",
       "\n",
       "MLP uses a fixed pattern of the size of the input image.\n",
       "\n",
       "CNNS use a pattern that is shifted accross the image domain to achieve translation invariance.\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "Markdown(\"\"\"\n",
    "    \n",
    "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
    "\n",
    "**YOUR ANSWER HERE**\n",
    "\n",
    "MLP uses a fixed pattern of the size of the input image.\n",
    "\n",
    "CNNS use a pattern that is shifted accross the image domain to achieve translation invariance.\n",
    "    \n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Is training the network with simultaneously the training dataset and the test dataset an issue or an advantage?\n",
    "\n",
    "Is tuning the network hyperparameters (i.e. number of layers, number of neurons, etc) with the use of the test set an issue or an advantage? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-21--10-18-03\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    \n",
       "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
       "\n",
       "**YOUR ANSWER HERE**\n",
       "\n",
       "For both questions, the issue is the same. \n",
       "\n",
       "The network will not generalize well to new/unseen data points because \n",
       "it will overfit perfectly the training set and the test set. \n",
       "\n",
       "This is the reason the test set is never used during parameter training or hyperparameter tuning.\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "Markdown(\"\"\"\n",
    "    \n",
    "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
    "\n",
    "**YOUR ANSWER HERE**\n",
    "\n",
    "For both questions, the issue is the same. \n",
    "\n",
    "The network will not generalize well to new/unseen data points because \n",
    "it will overfit perfectly the training set and the test set. \n",
    "\n",
    "This is the reason the test set is never used during parameter training or hyperparameter tuning.\n",
    "    \n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Consider a convolutional layer and an input image of size $(128,128)$ pixels.\n",
    "\n",
    "The goal is to generate an output activation map of size $(42,42)$ pixels with a convolutional filter of size $(3,3)$ pixels and stride value 3. \n",
    "\n",
    "What is the padding value of this convolutional layer?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-22--14-00-43\n",
      "42.666666666666664\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    \n",
       "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
       "\n",
       "**YOUR ANSWER HERE**\n",
       "\n",
       "padding value is p = 0 given the formula $\\lfloor  \\frac{n+2p-f}{s}+1 \\rfloor=42$ with $n=128, f=3, s=3$.\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from IPython.display import Markdown\n",
    "\n",
    "print((128+2*0-3)/3+1)\n",
    "\n",
    "Markdown(\"\"\"\n",
    "    \n",
    "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
    "\n",
    "**YOUR ANSWER HERE**\n",
    "\n",
    "padding value is p = 0 given the formula $\\\\lfloor  \\\\frac{n+2p-f}{s}+1 \\\\rfloor=42$ with $n=128, f=3, s=3$.\n",
    "    \n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Consider a 3-layer MLP neural network defined as\n",
    "\n",
    "$$y = U \\sigma (V \\sigma (W x))$$\n",
    "\n",
    "where $U$, $V$ and $W$ are the layer-wise trainable matrices, $\\sigma$ is the non-linear ReLU activation function, $x$ and $y$ are the input and output respectively.\n",
    "\n",
    "What is the reason to use two non-linear activation functions $\\sigma$?\n",
    "\n",
    "What is the number of parameters to learn when ReLU is used and when ReLU is not used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-21--10-18-03\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    \n",
       "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
       "\n",
       "**YOUR ANSWER HERE**\n",
       "\n",
       "The network degenerates to a single layer MLP, with limited learning capacity, \n",
       "when the two non-linear activation functions $\\sigma$ are not used.\n",
       "\n",
       "The number of parameters will be same as non-linear activation function has no parameters to learn.\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "Markdown(\"\"\"\n",
    "    \n",
    "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
    "\n",
    "**YOUR ANSWER HERE**\n",
    "\n",
    "The network degenerates to a single layer MLP, with limited learning capacity, \n",
    "when the two non-linear activation functions $\\sigma$ are not used.\n",
    "\n",
    "The number of parameters will be same as non-linear activation function has no parameters to learn.\n",
    "    \n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Compute the value of the output gradients $\\frac{\\partial L}{\\partial X}$ and $\\frac{\\partial L}{\\partial W}$ for the following activation layer :\n",
    "<img width=600 src=\"pic_ai6103_01a.png?arg\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20-10-21--10-18-03\n",
      "-143.30319999999998\n",
      "-88.51079999999999\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    \n",
       "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
       "\n",
       "**YOUR ANSWER HERE**\n",
       "\n",
       "$$\\frac{\\partial L}{\\partial X} = -143.3$$\n",
       "$$\\frac{\\partial L}{\\partial W} = -88.5$$\n",
       "\n",
       "<img width=800 src=\"pic_ai6103_01b.png?arg\">\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "from IPython.display import Markdown\n",
    "\n",
    "print(-(-4.1)*2*3.4*(2-2.1*3.4))\n",
    "print(-(-4.1)*2*2.1*(2-2.1*3.4))\n",
    "\n",
    "Markdown(\"\"\"\n",
    "    \n",
    "**DO NOT FORGET TO RUN THIS CELL TO GET A TIMESTAMP**\n",
    "\n",
    "**YOUR ANSWER HERE**\n",
    "\n",
    "$$\\\\frac{\\partial L}{\\partial X} = -143.3$$\n",
    "$$\\\\frac{\\partial L}{\\partial W} = -88.5$$\n",
    "\n",
    "<img width=800 src=\"pic_ai6103_01b.png?arg\">\n",
    "    \n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNd30TjgREYWyAkV0lT4iX6",
   "name": "CE_7454_coding_test_solution_Vijay.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
