{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI6103 DL Quiz Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import utils\n",
    "import time\n",
    "from torchsummary import summary\n",
    "from IPython.display import Math\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L01 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amount of data $n$ required to achieve super human performance: <br> \n",
    "$\\Large n = \\frac{\\mathit{features}}{error} = \\frac{d}{e}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "d = 1000*1000\n",
    "e = 1\n",
    "n = d//e; print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L02 - Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 2])\n",
      "tensor([1, 1, 2])\n",
      "tensor([6, 0, 4])\n"
     ]
    }
   ],
   "source": [
    "# Vector addition\n",
    "v1 = torch.LongTensor([1,1,2]); print(v1)\n",
    "v2 = torch.LongTensor([5,-1,2]); print(v1)\n",
    "vpv = v1 + v2 ;print(vpv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 2])\n",
      "tensor([2, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Vector multiplication\n",
    "c = 2 \n",
    "v1 = torch.LongTensor([1,1,2]); print(v1)\n",
    "cv = c*v1; print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 2])\n",
      "tensor([1, 1, 2])\n",
      "tensor(9)\n"
     ]
    }
   ],
   "source": [
    "## Inner product\n",
    "v1 = torch.LongTensor([1,1,2]); print(v1)\n",
    "v2 = torch.LongTensor([1,2,3]); print(v1)\n",
    "v1v2 = torch.matmul(v1, v2); print(v1v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 0]])\n",
      "tensor([[10, 10],\n",
      "        [20, 20],\n",
      "        [30, 30]])\n",
      "tensor([[11, 12],\n",
      "        [23, 24],\n",
      "        [35, 30]])\n"
     ]
    }
   ],
   "source": [
    "M1 = torch.LongTensor([[1,2], [3,4],[5,0]]); print(M1)\n",
    "M2 = torch.LongTensor([[10,10], [20,20],[30,30]]); print(M2)\n",
    "M1pM2 = M1+M2; print(M1pM2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 0]])\n",
      "tensor([[ 2,  4],\n",
      "        [ 6,  8],\n",
      "        [10,  0]])\n"
     ]
    }
   ],
   "source": [
    "c = 2\n",
    "M1 = torch.LongTensor([[1,2], [3,4],[5,0]]); print(M1)\n",
    "cM1 = c* M1; print(cM1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix-Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: torch.Size([2, 3])\n",
      "x: torch.Size([3])\n",
      "b: torch.Size([2])\n",
      "z: tensor([10, 16]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "W = torch.LongTensor([[1,2,3],[4,5,6]]); print(f\"W: {W.shape}\")\n",
    "x = torch.LongTensor([1,-2,2]); print(f\"x: {x.shape}\")\n",
    "b = torch.LongTensor([7, 10]); print(f\"b: {b.shape}\")\n",
    "z = torch.matmul(W,x)+b\n",
    "print(f\"z: {z} {z.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 4, 3, 3],\n",
      "        [8, 4, 5, 5]])\n"
     ]
    }
   ],
   "source": [
    "## Inner product\n",
    "A = torch.LongTensor([[1,1,1],[2,3,0]])\n",
    "B = torch.LongTensor([[1,2,1,1],[2,0,1,1],[3,2,1,1]])\n",
    "C = torch.mm(A,B)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner & Outer Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([1, 2, 3])\n",
      "tensor([0, 1, 2])\n",
      "tensor([[0, 1, 2],\n",
      "        [0, 2, 4],\n",
      "        [0, 3, 6]])\n",
      "tensor([[0, 1, 2],\n",
      "        [0, 2, 4],\n",
      "        [0, 3, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Outer product\n",
    "x = torch.LongTensor([1,2,3]); print(x) #3x1\n",
    "x1 = x.unsqueeze(1); print(x)\n",
    "y = torch.LongTensor([0,1,2]); print(y) #1x3\n",
    "\n",
    "outerpdt = x1 * y; print(outerpdt) #3x3\n",
    "outerpdt2 = torch.ger(x,y); print(outerpdt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L03 - Vanilla NN (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4.],\n",
      "        [1., 2., 5., 3.]]) torch.Size([2, 4])\n",
      "=> Softmax over dim 1 (rows)\n",
      "tensor([[0.0321, 0.0871, 0.2369, 0.6439],\n",
      "        [0.0152, 0.0414, 0.8310, 0.1125]])\n",
      "tensor([1., 1.])\n",
      "\n",
      "=> Softmax over dim 0 (cols)\n",
      "tensor([[0.5000, 0.5000, 0.1192, 0.7311],\n",
      "        [0.5000, 0.5000, 0.8808, 0.2689]])\n",
      "tensor(0.8808)\n",
      "tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "## Softmax\n",
    "B = torch.Tensor([[1,2,3,4],\n",
    "                 [1,2,5,3]])\n",
    "print(B, B.size()) # 2,4\n",
    "prob = F.softmax(B, dim=1) #rows (2) matrices\n",
    "print(f\"=> Softmax over dim 1 (rows)\")\n",
    "print(prob)\n",
    "print(prob.sum(1)) \n",
    "print(\"\")\n",
    "prob = F.softmax(B, dim=0) #cols (4) vectors\n",
    "print(f\"=> Softmax over dim 0 (cols)\")\n",
    "print(prob)\n",
    "print(torch.max(prob))\n",
    "print(prob.sum(0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3000, -0.2000,  0.8000, -0.2500]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "p_target = torch.Tensor([0,0,1,0])\n",
    "probs = torch.Tensor([0.3,0.2,0.2,0.25])\n",
    "err = p_target - probs; print(err, err.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1894, 0.4080, 0.5163, 0.7744, 0.3590, 0.5222, 0.6499, 0.6188, 0.7693,\n",
      "        0.6438, 0.4193, 0.2937, 0.0959, 0.9059, 0.3426, 0.1874, 0.9540, 0.6324,\n",
      "        0.1819, 0.2522, 0.7047, 0.5260, 0.1480, 0.3789, 0.1883, 0.5540, 0.8351,\n",
      "        0.5052, 0.9620, 0.8050, 0.4492, 0.1944])\n",
      "tensor([[-0.0568, -0.1224, -0.1549, -0.2323, -0.1077, -0.1566, -0.1950, -0.1856,\n",
      "         -0.2308, -0.1931, -0.1258, -0.0881, -0.0288, -0.2718, -0.1028, -0.0562,\n",
      "         -0.2862, -0.1897, -0.0546, -0.0757, -0.2114, -0.1578, -0.0444, -0.1137,\n",
      "         -0.0565, -0.1662, -0.2505, -0.1515, -0.2886, -0.2415, -0.1348, -0.0583],\n",
      "        [-0.0379, -0.0816, -0.1033, -0.1549, -0.0718, -0.1044, -0.1300, -0.1238,\n",
      "         -0.1539, -0.1288, -0.0839, -0.0587, -0.0192, -0.1812, -0.0685, -0.0375,\n",
      "         -0.1908, -0.1265, -0.0364, -0.0504, -0.1409, -0.1052, -0.0296, -0.0758,\n",
      "         -0.0377, -0.1108, -0.1670, -0.1010, -0.1924, -0.1610, -0.0898, -0.0389],\n",
      "        [ 0.1515,  0.3264,  0.4131,  0.6195,  0.2872,  0.4177,  0.5199,  0.4951,\n",
      "          0.6154,  0.5150,  0.3354,  0.2350,  0.0768,  0.7247,  0.2740,  0.1499,\n",
      "          0.7632,  0.5059,  0.1456,  0.2017,  0.5638,  0.4208,  0.1184,  0.3031,\n",
      "          0.1507,  0.4432,  0.6680,  0.4041,  0.7696,  0.6440,  0.3593,  0.1556],\n",
      "        [-0.0473, -0.1020, -0.1291, -0.1936, -0.0897, -0.1305, -0.1625, -0.1547,\n",
      "         -0.1923, -0.1610, -0.1048, -0.0734, -0.0240, -0.2265, -0.0856, -0.0468,\n",
      "         -0.2385, -0.1581, -0.0455, -0.0630, -0.1762, -0.1315, -0.0370, -0.0947,\n",
      "         -0.0471, -0.1385, -0.2088, -0.1263, -0.2405, -0.2012, -0.1123, -0.0486]]) torch.Size([4, 32])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((32)); print(x)\n",
    "# ex = err.unsqueeze(1) * x; print(ex, ex.shape)\n",
    "ex2 = torch.ger(err,x); print(ex2, ex2.shape) #torch.ger == torch.outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L04 - Vanilla NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: \n",
    "            continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------+\n",
      "|       Modules       | Parameters |\n",
      "+---------------------+------------+\n",
      "| linear_layer.weight |    7840    |\n",
      "|  linear_layer.bias  |     10     |\n",
      "+---------------------+------------+\n",
      "Total Trainable Params: 7850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7850"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class One_Layer_Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(One_Layer_Net, self).__init__()\n",
    "        self.linear_layer = nn.Linear(input_size,output_size,bias=True)\n",
    "    def forward(self, x): \n",
    "#         x = self.linear_layer(x)\n",
    "#         p = F.softmax(x, dim=1)\n",
    "        return p\n",
    "    \n",
    "net = One_Layer_Net(784, 10)\n",
    "\n",
    "\n",
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+\n",
      "|    Modules     | Parameters |\n",
      "+----------------+------------+\n",
      "|  conv1.weight  |    450     |\n",
      "|   conv1.bias   |     50     |\n",
      "|  conv2.weight  |   45000    |\n",
      "|   conv2.bias   |    100     |\n",
      "| linear1.weight |   490000   |\n",
      "|  linear1.bias  |    100     |\n",
      "| linear2.weight |    1000    |\n",
      "|  linear2.bias  |     10     |\n",
      "+----------------+------------+\n",
      "Total Trainable Params: 536710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "536710"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LeNet5_convnet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet5_convnet, self).__init__()\n",
    "        # CL1:   28 x 28  -->    50 x 28 x 28 \n",
    "        self.conv1 = nn.Conv2d(1,   50,  kernel_size=3,  padding=1 )\n",
    "        # MP1: 50 x 28 x 28 -->    50 x 14 x 14\n",
    "        self.pool1  = nn.MaxPool2d(2,2)\n",
    "        # CL2:   50 x 14 x 14  -->    100 x 14 x 14 \n",
    "        self.conv2 = nn.Conv2d(50, 100,  kernel_size=3,  padding=1 ) # COMPLETE HERE\n",
    "        # MP2: 100 x 14 x 14 -->    100 x 7 x 7\n",
    "        self.pool2 = nn.MaxPool2d(2,2) # COMPLETE HERE\n",
    "        # LL1:   100 x 7 x 7 = 4900 -->  100 \n",
    "        self.linear1 = nn.Linear(4900, 100) # COMPLETE HERE\n",
    "        # LL2:   100  -->  10 \n",
    "        self.linear2 = nn.Linear(100, 10) # COMPLETE HERE\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "#         # CL1:   28 x 28  -->    50 x 28 x 28 \n",
    "#         x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "#         # MP1: 50 x 28 x 28 -->    50 x 14 x 14\n",
    "#         x = self.pool1(x)\n",
    "#         # CL2:   50 x 14 x 14  -->    100 x 14 x 14\n",
    "#         x = self.conv2(x) # COMPLETE HERE\n",
    "#         x = F.relu(x) # COMPLETE HERE\n",
    "#         # MP2: 100 x 14 x 14 -->    100 x 7 x 7\n",
    "#         x = self.pool2(x) # COMPLETE HERE\n",
    "#         # LL1:   100 x 7 x 7 = 4900  -->  100 \n",
    "#         x = x.view(-1, 4900)\n",
    "#         x = self.linear1(x) # COMPLETE HERE\n",
    "#         x = F.relu(x)# COMPLETE HERE\n",
    "#         # LL2:   4900  -->  10 \n",
    "#         x = self.linear2(x) # COMPLETE HERE\n",
    "        return x\n",
    "    \n",
    "conv = LeNet5_convnet()\n",
    "count_parameters(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5_convnet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet5_convnet, self).__init__()\n",
    "        # CL1:   28 x 28  -->    50 x 28 x 28 \n",
    "        self.conv1 = nn.Conv2d(1,   50,  kernel_size=3,  padding=1 )\n",
    "        # MP1: 50 x 28 x 28 -->    50 x 14 x 14\n",
    "        self.pool1  = nn.MaxPool2d(2,2)\n",
    "        # CL2:   50 x 14 x 14  -->    100 x 14 x 14 \n",
    "        self.conv2 = nn.Conv2d(50, 100,  kernel_size=3,  padding=1 ) # COMPLETE HERE\n",
    "        # MP2: 100 x 14 x 14 -->    100 x 7 x 7\n",
    "        self.pool2 = nn.MaxPool2d(2,2) # COMPLETE HERE\n",
    "        # LL1:   100 x 7 x 7 = 4900 -->  100 \n",
    "        self.linear1 = nn.Linear(4900, 100) # COMPLETE HERE\n",
    "        # LL2:   100  -->  10 \n",
    "        self.linear2 = nn.Linear(100, 10) # COMPLETE HERE\n",
    "\n",
    "\n",
    "    def forward(self, x):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_conv_filter(I: int, O: int, P:int = 0, S:int=1):\n",
    "    assert S > 0\n",
    "    f = I + 2*P - S*(O-1)\n",
    "    print(f\"CONV filter size for I:{I} O:{O}, padding:{P} stride:{S} = {f}\")\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONV filter size for I:32 O:28, padding:0 stride:1 = 5\n",
      "CONV filter size for I:14 O:10, padding:0 stride:1 = 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_conv_filter(32, 28, 0, 1)\n",
    "cal_conv_filter(14, 10, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONV filter size for I:128 O:42, padding:0 stride:3 = 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_conv_filter(128, 42, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_max_pool(I: int, O: int):\n",
    "    # P == 0, S == f\n",
    "    f = I//O\n",
    "    print(f\"MP filter size for I:{I} O:{O} = {f}\")\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MP filter size for I:28 O:14 = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_max_pool(28, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
