{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI6103 DL Quiz Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import utils\n",
    "import time\n",
    "from torchsummary import summary\n",
    "from IPython.display import Math\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L01 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amount of data $n$ required to achieve super human performance: <br> \n",
    "$\\Large n = \\frac{\\mathit{features}}{error} = \\frac{d}{e}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "d = 1000*1000\n",
    "e = 1\n",
    "n = d//e; print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L02 - Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 2])\n",
      "tensor([1, 1, 2])\n",
      "tensor([6, 0, 4])\n"
     ]
    }
   ],
   "source": [
    "# Vector addition\n",
    "v1 = torch.LongTensor([1,1,2]); print(v1)\n",
    "v2 = torch.LongTensor([5,-1,2]); print(v1)\n",
    "vpv = v1 + v2 ;print(vpv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 2])\n",
      "tensor([2, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Vector multiplication\n",
    "c = 2 \n",
    "v1 = torch.LongTensor([1,1,2]); print(v1)\n",
    "cv = c*v1; print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 2])\n",
      "tensor([1, 1, 2])\n",
      "tensor(9)\n"
     ]
    }
   ],
   "source": [
    "## Inner product\n",
    "v1 = torch.LongTensor([1,1,2]); print(v1)\n",
    "v2 = torch.LongTensor([1,2,3]); print(v1)\n",
    "v1v2 = torch.matmul(v1, v2); print(v1v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 0]])\n",
      "tensor([[10, 10],\n",
      "        [20, 20],\n",
      "        [30, 30]])\n",
      "tensor([[11, 12],\n",
      "        [23, 24],\n",
      "        [35, 30]])\n"
     ]
    }
   ],
   "source": [
    "M1 = torch.LongTensor([[1,2], [3,4],[5,0]]); print(M1)\n",
    "M2 = torch.LongTensor([[10,10], [20,20],[30,30]]); print(M2)\n",
    "M1pM2 = M1+M2; print(M1pM2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 0]])\n",
      "tensor([[ 2,  4],\n",
      "        [ 6,  8],\n",
      "        [10,  0]])\n"
     ]
    }
   ],
   "source": [
    "c = 2\n",
    "M1 = torch.LongTensor([[1,2], [3,4],[5,0]]); print(M1)\n",
    "cM1 = c* M1; print(cM1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix-Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: torch.Size([2, 3])\n",
      "x: torch.Size([3])\n",
      "b: torch.Size([2])\n",
      "z: tensor([10, 16]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "W = torch.LongTensor([[1,2,3],[4,5,6]]); print(f\"W: {W.shape}\")\n",
    "x = torch.LongTensor([1,-2,2]); print(f\"x: {x.shape}\")\n",
    "b = torch.LongTensor([7, 10]); print(f\"b: {b.shape}\")\n",
    "z = torch.matmul(W,x)+b\n",
    "print(f\"z: {z} {z.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 4, 3, 3],\n",
      "        [8, 4, 5, 5]])\n"
     ]
    }
   ],
   "source": [
    "## Inner product\n",
    "A = torch.LongTensor([[1,1,1],[2,3,0]])\n",
    "B = torch.LongTensor([[1,2,1,1],[2,0,1,1],[3,2,1,1]])\n",
    "C = torch.mm(A,B)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner & Outer Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([1, 2, 3])\n",
      "tensor([0, 1, 2])\n",
      "tensor([[0, 1, 2],\n",
      "        [0, 2, 4],\n",
      "        [0, 3, 6]])\n",
      "tensor([[0, 1, 2],\n",
      "        [0, 2, 4],\n",
      "        [0, 3, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Outer product\n",
    "x = torch.LongTensor([1,2,3]); print(x) #3x1\n",
    "x1 = x.unsqueeze(1); print(x)\n",
    "y = torch.LongTensor([0,1,2]); print(y) #1x3\n",
    "\n",
    "outerpdt = x1 * y; print(outerpdt) #3x3\n",
    "outerpdt2 = torch.ger(x,y); print(outerpdt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L03 - Vanilla NN (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4.],\n",
      "        [1., 2., 5., 3.]]) torch.Size([2, 4])\n",
      "=> Softmax over dim 1 (rows)\n",
      "tensor([[0.0321, 0.0871, 0.2369, 0.6439],\n",
      "        [0.0152, 0.0414, 0.8310, 0.1125]])\n",
      "tensor([1., 1.])\n",
      "\n",
      "=> Softmax over dim 0 (cols)\n",
      "tensor([[0.5000, 0.5000, 0.1192, 0.7311],\n",
      "        [0.5000, 0.5000, 0.8808, 0.2689]])\n",
      "tensor(0.8808)\n",
      "tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "## Softmax\n",
    "B = torch.Tensor([[1,2,3,4],\n",
    "                 [1,2,5,3]])\n",
    "print(B, B.size()) # 2,4\n",
    "prob = F.softmax(B, dim=1) #rows (2) matrices\n",
    "print(f\"=> Softmax over dim 1 (rows)\")\n",
    "print(prob)\n",
    "print(prob.sum(1)) \n",
    "print(\"\")\n",
    "prob = F.softmax(B, dim=0) #cols (4) vectors\n",
    "print(f\"=> Softmax over dim 0 (cols)\")\n",
    "print(prob)\n",
    "print(torch.max(prob))\n",
    "print(prob.sum(0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3000, -0.2000,  0.8000, -0.2500]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "p_target = torch.Tensor([0,0,1,0])\n",
    "probs = torch.Tensor([0.3,0.2,0.2,0.25])\n",
    "err = p_target - probs; print(err, err.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5811, 0.6185, 0.0312, 0.8114, 0.6974, 0.2686, 0.8709, 0.8985, 0.7329,\n",
      "        0.2885, 0.0538, 0.1365, 0.0124, 0.8025, 0.5752, 0.2375, 0.1508, 0.8208,\n",
      "        0.7744, 0.3925, 0.2184, 0.6947, 0.1085, 0.0444, 0.6231, 0.3180, 0.1898,\n",
      "        0.0459, 0.8153, 0.3576, 0.5790, 0.1936])\n",
      "tensor([[-0.1743, -0.1856, -0.0094, -0.2434, -0.2092, -0.0806, -0.2613, -0.2695,\n",
      "         -0.2199, -0.0865, -0.0161, -0.0409, -0.0037, -0.2407, -0.1726, -0.0712,\n",
      "         -0.0452, -0.2462, -0.2323, -0.1177, -0.0655, -0.2084, -0.0325, -0.0133,\n",
      "         -0.1869, -0.0954, -0.0569, -0.0138, -0.2446, -0.1073, -0.1737, -0.0581],\n",
      "        [-0.1162, -0.1237, -0.0062, -0.1623, -0.1395, -0.0537, -0.1742, -0.1797,\n",
      "         -0.1466, -0.0577, -0.0108, -0.0273, -0.0025, -0.1605, -0.1150, -0.0475,\n",
      "         -0.0302, -0.1642, -0.1549, -0.0785, -0.0437, -0.1389, -0.0217, -0.0089,\n",
      "         -0.1246, -0.0636, -0.0380, -0.0092, -0.1631, -0.0715, -0.1158, -0.0387],\n",
      "        [ 0.4649,  0.4948,  0.0250,  0.6491,  0.5580,  0.2149,  0.6967,  0.7188,\n",
      "          0.5863,  0.2308,  0.0430,  0.1092,  0.0099,  0.6420,  0.4602,  0.1900,\n",
      "          0.1206,  0.6567,  0.6195,  0.3140,  0.1747,  0.5558,  0.0868,  0.0355,\n",
      "          0.4985,  0.2544,  0.1518,  0.0367,  0.6522,  0.2861,  0.4632,  0.1549],\n",
      "        [-0.1453, -0.1546, -0.0078, -0.2029, -0.1744, -0.0672, -0.2177, -0.2246,\n",
      "         -0.1832, -0.0721, -0.0135, -0.0341, -0.0031, -0.2006, -0.1438, -0.0594,\n",
      "         -0.0377, -0.2052, -0.1936, -0.0981, -0.0546, -0.1737, -0.0271, -0.0111,\n",
      "         -0.1558, -0.0795, -0.0474, -0.0115, -0.2038, -0.0894, -0.1447, -0.0484]]) torch.Size([4, 32])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((32)); print(x)\n",
    "# ex = err.unsqueeze(1) * x; print(ex, ex.shape)\n",
    "ex2 = torch.ger(err,x); print(ex2, ex2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L04 - Vanilla NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------+\n",
      "|       Modules       | Parameters |\n",
      "+---------------------+------------+\n",
      "| linear_layer.weight |    7840    |\n",
      "|  linear_layer.bias  |     10     |\n",
      "+---------------------+------------+\n",
      "Total Trainable Params: 7850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7850"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class One_Layer_Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(One_Layer_Net, self).__init__()\n",
    "        self.linear_layer = nn.Linear(input_size,output_size,bias=True)\n",
    "    def forward(self, x): \n",
    "        x = self.linear_layer(x)\n",
    "        p = F.softmax(x, dim=1)\n",
    "        return p\n",
    "    \n",
    "net = One_Layer_Net(784, 10)\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: \n",
    "            continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+\n",
      "|    Modules     | Parameters |\n",
      "+----------------+------------+\n",
      "|  conv1.weight  |    450     |\n",
      "|   conv1.bias   |     50     |\n",
      "|  conv2.weight  |   45000    |\n",
      "|   conv2.bias   |    100     |\n",
      "| linear1.weight |   490000   |\n",
      "|  linear1.bias  |    100     |\n",
      "| linear2.weight |    1000    |\n",
      "|  linear2.bias  |     10     |\n",
      "+----------------+------------+\n",
      "Total Trainable Params: 536710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "536710"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LeNet5_convnet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(LeNet5_convnet, self).__init__()\n",
    "\n",
    "        # CL1:   28 x 28  -->    50 x 28 x 28 \n",
    "        self.conv1 = nn.Conv2d(1,   50,  kernel_size=3,  padding=1 )\n",
    "        \n",
    "        # MP1: 50 x 28 x 28 -->    50 x 14 x 14\n",
    "        self.pool1  = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # CL2:   50 x 14 x 14  -->    100 x 14 x 14 \n",
    "        self.conv2 = nn.Conv2d(50,   100,  kernel_size=3,  padding=1 ) # COMPLETE HERE\n",
    "        \n",
    "        # MP2: 100 x 14 x 14 -->    100 x 7 x 7\n",
    "        self.pool2 = nn.MaxPool2d(2,2) # COMPLETE HERE\n",
    "        \n",
    "        # LL1:   100 x 7 x 7 = 4900 -->  100 \n",
    "        self.linear1 = nn.Linear(4900, 100) # COMPLETE HERE\n",
    "        \n",
    "        # LL2:   100  -->  10 \n",
    "        self.linear2 = nn.Linear(100, 10) # COMPLETE HERE\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # CL1:   28 x 28  -->    50 x 28 x 28 \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # MP1: 50 x 28 x 28 -->    50 x 14 x 14\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # CL2:   50 x 14 x 14  -->    100 x 14 x 14\n",
    "        x = self.conv2(x) # COMPLETE HERE\n",
    "        x = F.relu(x) # COMPLETE HERE\n",
    "        \n",
    "        # MP2: 100 x 14 x 14 -->    100 x 7 x 7\n",
    "        x = self.pool2(x) # COMPLETE HERE\n",
    "\n",
    "        # LL1:   100 x 7 x 7 = 4900  -->  100 \n",
    "        x = x.view(-1, 4900)\n",
    "        x = self.linear1(x) # COMPLETE HERE\n",
    "        x = F.relu(x)# COMPLETE HERE\n",
    "        \n",
    "        # LL2:   4900  -->  10 \n",
    "        x = self.linear2(x) # COMPLETE HERE\n",
    "    \n",
    "        return x\n",
    "    \n",
    "conv = LeNet5_convnet()\n",
    "count_parameters(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
